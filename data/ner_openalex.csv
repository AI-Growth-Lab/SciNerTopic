id,doi,title,publication_year,abstract
https://openalex.org/W2143933463,https://doi.org/10.1016/j.ipm.2014.10.006,Analysis of named entity recognition and linking for tweets,2015,"Applying natural language processing for mining and intelligent information access to tweets (a form of microblog) is a challenging, emerging research area. Unlike carefully authored news text other longer content, pose number new challenges, due their short, noisy, context-dependent, dynamic nature. Information extraction from typically performed in pipeline, comprising consecutive stages identification, tokenisation, part-of-speech tagging, named entity recognition disambiguation (e.g. with respect DBpedia). In this work, we describe Twitter dataset, conduct an empirical analysis disambiguation, investigating how robust state-of-the-art systems are on such noisy texts, what the main sources error are, which problems should be further investigated improve state art."
https://openalex.org/W2963855739,https://doi.org/10.18653/v1/k16-1025,Joint Learning of the Embedding of Words and Entities for Named Entity Disambiguation,2016,"Named Entity Disambiguation (NED) refers to the task of resolving multiple named entity mentions in a document their correct references knowledge base (KB) (e.g., Wikipedia). In this paper, we propose novel embedding method specifically designed for NED. The proposed jointly maps words and entities into same continuous vector space. We extend skip-gram model by using two models. KB graph learns relatedness link structure KB, whereas anchor context aims align vectors such that similar occur close one another space leveraging anchors words. By combining contexts based on with standard NED features, achieved state-of-the-art accuracy 93.1% CoNLL dataset 85.2% TAC 2010 dataset."
https://openalex.org/W2414378847,https://doi.org/10.1093/bioinformatics/btw343,TaggerOne: joint named entity recognition and normalization with semi-Markov Models,2016,"Text mining is increasingly used to manage the accelerating pace of biomedical literature. Many text applications depend on accurate named entity recognition (NER) and normalization (grounding). While high performing machine learning methods trainable for many types exist NER, are usually specialized a single type. NER systems also typically in serial pipeline, causing cascading errors limiting ability system directly exploit lexical information provided by normalization.We propose first model joint during both training prediction. The arbitrary consists semi-Markov structured linear classifier, with rich feature approach supervised semantic indexing normalization. We introduce TaggerOne, Java implementation our as general toolkit TaggerOne not specific any type, requiring only annotated data corresponding lexicon, has been optimized throughput.We validated multiple gold-standard corpora containing mention- concept-level annotations. Benchmarking results show that achieves performance diseases (NCBI Disease corpus, f-score: 0.829, 0.807) chemicals (BioCreative 5 CDR 0.914, f-score 0.895). These compare favorably previous state art, notwithstanding greater flexibility model. conclude jointly modeling greatly improves performance.The source code an online demonstration available at: http://www.ncbi.nlm.nih.gov/bionlp/taggeronezhiyong.lu@nih.govSupplementary at Bioinformatics online."
https://openalex.org/W3104186312,https://doi.org/10.18653/v1/2020.emnlp-demos.2,BERTweet: A pre-trained language model for English Tweets,2020,"We present BERTweet, the first public large-scale pre-trained language model for English Tweets. Our having same architecture as BERT-base (Devlin et al., 2019), is trained using RoBERTa pre-training procedure (Liu 2019). Experiments show that BERTweet outperforms strong baselines RoBERTa-base and XLM-R-base (Conneau 2020), producing better performance results than previous state-of-the-art models on three Tweet NLP tasks: Part-of-speech tagging, Named-entity recognition text classification. release under MIT License to facilitate future research applications data. available at https://github.com/VinAIResearch/BERTweet"
https://openalex.org/W3035375600,https://doi.org/10.18653/v1/2020.acl-main.577,Named Entity Recognition as Dependency Parsing,2020,"Named Entity Recognition (NER) is a fundamental task in Natural Language Processing, concerned with identifying spans of text expressing references to entities. NER research often focused on flat entities only (flat NER), ignoring the fact that entity can be nested, as [Bank [China]] (Finkel and Manning, 2009). In this paper, we use ideas from graph-based dependency parsing provide our model global view input via biaffine (Dozat 2017). The scores pairs start end tokens sentence which explore all spans, so able predict named accurately. We show works well for both nested through evaluation 8 corpora achieving SoTA performance them, accuracy gains up 2.2 percentage points."
https://openalex.org/W2963738950,https://doi.org/10.18653/v1/d17-2017,NeuroNER: an easy-to-use program for named-entity recognition based on neural networks,2017,"Named-entity recognition (NER) aims at identifying entities of interest in a text. Artificial neural networks (ANNs) have recently been shown to outperform existing NER systems. However, ANNs remain challenging use for non-expert users. In this paper, we present NeuroNER, an easy-to-use named-entity tool based on ANNs. Users can annotate using graphical web-based user interface (BRAT): the annotations are then used train ANN, which turn predict entities’ locations and categories new texts. NeuroNER makes annotation-training-prediction flow smooth accessible anyone."
https://openalex.org/W2293502436,https://doi.org/10.3115/v1/n15-1146,MPQA 3.0: An Entity/Event-Level Sentiment Corpus,2015,"This paper presents an annotation scheme for adding entity and event target annotations to the MPQA corpus, a rich span-annotated opinion corpus. The new corpus promises be valuable resource developing systems entity/event-level sentiment analysis. Such systems, in turn, would NLP applications such as Automatic Question Answering. We introduce idea of targets (eTargets), describe scheme, present results agreement study."
https://openalex.org/W2337969891,https://doi.org/10.1145/2911451.2911535,Robust and Collective Entity Disambiguation through Semantic Embeddings,2016,"Entity disambiguation is the task of mapping ambiguous terms in natural-language text to its entities a knowledge base. It finds application extraction structured data RDF (Resource Description Framework) from textual documents, but equally so facilitating artificial intelligence applications, such as Semantic Search, Reasoning and Question & Answering. We propose new collective, graph-based algorithm utilizing semantic entity document embeddings for robust disambiguation. Robust thereby refers property achieving better than state-of-the-art results over wide range very different sets. Our approach also able abstain if no appropriate can be found specific surface form. evaluation shows, that our achieves significantly (>5%) all other publicly available algorithms on 7 9 datasets without set tuning. Moreover, we discuss influence quality base accuracy indicate non-publicly algorithms."
https://openalex.org/W2682408236,https://doi.org/10.1371/journal.pone.0179488,A rule-based named-entity recognition method for knowledge extraction of evidence-based dietary recommendations,2017,"Evidence-based dietary information represented as unstructured text is a crucial that needs to be accessed in order help dietitians follow the new knowledge arrives daily with newly published scientific reports. Different named-entity recognition (NER) methods have been introduced previously extract useful from biomedical literature. They are focused on, for example extracting gene mentions, proteins relationships between genes and proteins, chemical concepts drugs diseases. In this paper, we present novel NER method, called drNER, extraction of evidence-based information. To best our first attempt at concepts. DrNER rule-based consists two phases. The one involves detection determination entities mention, second selection entities. We evaluate method by using corpora heterogeneous sources, including several scientifically validated web sites publications. Evaluation showed drNER gives good results can used recommendations."
https://openalex.org/W3105491236,https://doi.org/10.1186/s12859-019-2813-6,CollaboNet: collaboration of deep neural networks for biomedical named entity recognition,2018,"Background: Finding biomedical named entities is one of the most essential tasks in text mining. Recently, deep learning-based approaches have been applied to entity recognition (BioNER) and showed promising results. However, as learning need an abundant amount training data, a lack data can hinder performance. BioNER datasets are scarce resources each dataset covers only small subset types. Furthermore, many bio polysemous, which major obstacles recognition. Results: To address type misclassification problem, we propose CollaboNet utilizes combination multiple NER models. In CollaboNet, models trained on different connected other so that target model obtains information from collaborator reduce false positives. Every expert their takes turns serving during time. The experimental results show be used greatly number positives misclassified including polysemous words. achieved state-of-the-art performance terms precision, recall F1 score. Conclusions: We demonstrated benefits combining for BioNER. Our has successfully reduced improved by leveraging annotated Given our model, believe improve accuracy downstream mining applications such bio-entity relation extraction."
https://openalex.org/W2889869899,https://doi.org/10.18653/v1/d18-1306,Marginal Likelihood Training of BiLSTM-CRF for Biomedical Named Entity Recognition from Disjoint Label Sets,2018,"Extracting typed entity mentions from text is a fundamental component to language understanding and reasoning. While there exist substantial labeled datasets for multiple subsets of biomedical types—such as genes proteins, or chemicals diseases—it rare find large containing labels all desired types together. This paper presents method training single CRF extractor with disjoint partially overlapping sets types. Our approach employs marginal likelihood insist on that are present in the data, while filling “missing labels”. allows us leverage available data within model. In experimental results Biocreative V CDR (chemicals/diseases), VI ChemProt (chemicals/proteins) MedMentions (19 types) datasets, we show joint improves NER F1 over isolation, our methods achieve state-of-the-art results."
https://openalex.org/W2471349142,https://doi.org/10.1162/tacl_a_00094,J-NERD: Joint Named Entity Recognition and Disambiguation with Rich Linguistic Features,2016,"Methods for Named Entity Recognition and Disambiguation (NERD) perform NER NED in two separate stages. Therefore, may be penalized with respect to precision by false positives, suffers recall from negatives. Conversely, does not fully exploit information computed such as types of mentions. This paper presents J-NERD, a new approach jointly, means probabilistic graphical model that captures mention spans, types, the mapping mentions entities knowledge base. We present experiments different kinds texts CoNLL’03, ACE’05, ClueWeb’09-FACC1 corpora. J-NERD consistently outperforms state-of-the-art competitors end-to-end NERD precision, recall, F1."
https://openalex.org/W2950333738,https://doi.org/10.18653/v1/p19-2026,Joint Learning of Named Entity Recognition and Entity Linking,2019,"Named entity recognition (NER) and linking (EL) are two fundamentally related tasks, since in order to perform EL, first the mentions entities have be detected. However, most approaches disregard mention detection part, assuming that correct been previously In this paper, we joint learning of NER EL leverage their relatedness obtain a more robust generalisable system. For that, introduce model inspired by Stack-LSTM approach. We observe fact, doing multi-task improves performance both tasks when comparing with models trained individual objectives. Furthermore, achieve results competitive state-of-the-art EL."
https://openalex.org/W3035097673,https://doi.org/10.18653/v1/2020.acl-main.139,Named Entity Recognition without Labelled Data: A Weak Supervision Approach,2020,"Named Entity Recognition (NER) performance often degrades rapidly when applied to target domains that differ from the texts observed during training. When in-domain labelled data is available, transfer learning techniques can be used adapt existing NER models domain. But what should one do there no hand-labelled for domain? This paper presents a simple but powerful approach learn in absence of through weak supervision. The relies on broad spectrum labelling functions automatically annotate These annotations are then merged together using hidden Markov model which captures varying accuracies and confusions functions. A sequence finally trained basis this unified annotation. We evaluate two English datasets (CoNLL 2003 news articles Reuters Bloomberg) demonstrate an improvement about 7 percentage points entity-level F1 scores compared out-of-domain neural model."
https://openalex.org/W3082330004,https://doi.org/10.3389/fcell.2020.00673,Named Entity Recognition and Relation Detection for Biomedical Information Extraction,2020,"The number of scientific publications in the literature is steadily growing, containing our knowledge biomedical, health, and clinical sciences. Since there currently no automatic archiving obtained results, much this information remains buried textual details not readily available for further usage or analysis. For reason, natural language processing (NLP) text mining methods are used extraction from such publications. In paper, we review practices Named Entity Recognition (NER) Relation Detection (RD), allowing, e.g., to identify interactions between proteins drugs genes diseases. This can be integrated into networks summarize large-scale on a particular biomedical problem, which then amenable easy data management Furthermore, survey novel deep learning that have recently been introduced tasks."
https://openalex.org/W2761714433,https://doi.org/10.1186/s12859-017-1857-8,A method for named entity normalization in biomedical articles: application to diseases and plants,2017,"In biomedical articles, a named entity recognition (NER) technique that identifies names from texts is an important element for extracting biological knowledge articles. After NER applied to the next step normalize identified into standard concepts (i.e., disease are mapped National Library of Medicine's Medical Subject Headings terms). many normalization methods rely on domain-specific dictionaries resolving synonyms and abbreviations. However, not comprehensive except some entities such as genes. recent years, articles have accumulated rapidly, neural network-based algorithms incorporate large amount unlabeled data shown considerable success in several natural language processing problems.In this study, we propose approach normalizing entities, plant names, by using word embeddings represent semantic spaces. For diseases, training Center Biotechnology Information (NCBI) corpus PubMed abstracts were used construct representations. plants, manually constructed vectors. We showed proposed performed better than use only or accuracy was improved our model even when comprehensive. obtained F-scores 0.808 0.690 NCBI corpus, respectively. further evaluated set task BioCreative V challenge. When dictionary, significantly outperformed best system task.The shows robust performance entities. The available at http://gcancer.org/plant http://gcancer.org/normalization ,"
https://openalex.org/W2984147501,https://doi.org/10.18653/v1/k19-1063,Investigating Entity Knowledge in BERT with Simple Neural End-To-End Entity Linking,2020,"A typical architecture for end-to-end entity linking systems consists of three steps: mention detection, candidate generation and disambiguation. In this study we investigate the following questions: (a) Can all those steps be learned jointly with a model contextualized text-representations, i.e. BERT (Devlin et al., 2019)? (b) How much knowledge is already contained in pretrained BERT? (c) Does additional improve BERT's performance downstream tasks? To end, propose an extreme simplification setup that works surprisingly well: simply cast it as per token classification over entire vocabulary (over 700K classes our case). We show on benchmark (i) improves representations plain BERT, (ii) outperforms architectures optimize tasks separately (iii) only comes second to current state-of-the-art does detection disambiguation jointly. Additionally, usefulness entity-aware token-representations text-understanding GLUE, well question answering benchmarks SQUAD V2 SWAG also EN-DE WMT14 machine translation benchmark. surprise, find most do not benefit from knowledge, except task very small training data, RTE which by 2%."
https://openalex.org/W2949257977,https://doi.org/10.18653/v1/p19-1138,Multi-grained Named Entity Recognition,2019,"This paper presents a novel framework, MGNER, for Multi-Grained Named Entity Recognition where multiple entities or entity mentions in sentence could be non-overlapping totally nested. Different from traditional approaches regarding NER as sequential labeling task and annotate consecutively, MGNER detects recognizes on granularities: it is able to recognize named without explicitly assuming nested structures. consists of Detector that examines all possible word segments Classifier categorizes entities. In addition, contextual information self-attention mechanism are utilized throughout the framework improve performance. Experimental results show outperforms current state-of-the-art baselines up 4.4% terms F1 score among nested/non-overlapping tasks."
https://openalex.org/W2250758064,https://doi.org/10.18653/v1/d15-1081,Language and Domain Independent Entity Linking with Quantified Collective Validation,2015,"Linking named mentions detected in a source document to an existing knowledge base provides disambiguated entity referents for the mentions. This allows better analysis, extraction and population. Most of previous research extensively exploited linguistic features documents supervised or semi-supervised way. These systems therefore cannot be easily applied new language domain. In this paper, we present novel unsupervised algorithm Quantified Collective Validation that avoids excessive analysis on fully leverages structure linking task. We show our approach achieves stateof-the-art English performance demonstrate successful deployment (Chinese) two domains (Biomedical Earth Science). Experiment datasets system demonstration are available at http://tw.rpi.edu/web/doc/ hanwang_emnlp_2015 purpose."
https://openalex.org/W2250999864,https://doi.org/10.18653/v1/w15-4320,Enhancing Named Entity Recognition in Twitter Messages Using Entity Linking,2015,"In this paper, we describe our approach for Named Entity Recognition in Twitter, a shared task ACL 2015 Workshop on Noisy User-generated Text (Baldwin et al., 2015). Because of the noisy, short, and colloquial nature performance (NER) degrades significantly. To address problem, propose novel method to enhance Twitter NER by using Linking which is detecting entity mentions text resolving them corresponding entries knowledge bases such as Wikipedia. Our based supervised machine-learning uses highquality obtained from several open bases. comparison with other systems proposed task, achieved best performance."
https://openalex.org/W2757016069,https://doi.org/10.18653/v1/w17-4422,Transfer Learning and Sentence Level Features for Named Entity Recognition on Tweets,2017,"We present our system for the WNUT 2017 Named Entity Recognition challenge on Twitter data. describe two modifications of a basic neural network architecture sequence tagging. First, we show how exploit additional labeled data, where tags differ from target task. Then, propose way to incorporate sentence level features. Our uses both methods and ranked second entity annotations, achieving an F1-score 40.78, surface form 39.33."
https://openalex.org/W2463000881,https://doi.org/10.18653/v1/n16-1029,Name Tagging for Low-resource Incident Languages based on Expectation-driven Learning,2016,"In this paper we tackle a challenging name tagging problem in an emergent setting the tagger needs to be complete within few hours for new incident language (IL) using very resources. Inspired by observing how human annotators attack challenge, propose expectation-driven learning framework. framework rapidly acquire, categorize, structure and zoom on ILspecific expectations (rules, features, patterns, gazetteers, etc.) from various non-traditional sources: consulting encoding linguistic knowledge native speakers, mining projecting patterns both mono-lingual cross-lingual corpora, typing based entity linking. We also cost-aware combination approach compose expectations. Experiments seven low-resource languages demonstrate effectiveness generality of framework: are able setup IL two hours, achieve 33.8%-65.1% F-score 1."
https://openalex.org/W3034340683,https://doi.org/10.18653/v1/2020.acl-main.752,TriggerNER: Learning with Entity Triggers as Explanations for Named Entity Recognition,2020,"Training neural models for named entity recognition (NER) in a new domain often requires additional human annotations (e.g., tens of thousands labeled instances) that are usually expensive and time-consuming to collect. Thus, crucial research question is how obtain supervision cost-effective way. In this paper, we introduce ""entity triggers,"" an effective proxy explanations facilitating label-efficient learning NER models. An trigger defined as group words sentence helps explain why humans would recognize the sentence. We crowd-sourced 14k triggers two well-studied datasets. Our proposed model, Trigger Matching Network, jointly learns representations soft matching module with self-attention such can generalize unseen sentences easily tagging. framework significantly more than traditional frameworks. Experiments show using only 20% trigger-annotated results comparable performance 70% conventional annotated sentences."
https://openalex.org/W2971039193,https://doi.org/10.18653/v1/d19-1519,CrossWeigh: Training Named Entity Tagger from Imperfect Annotations,2019,"Everyone makes mistakes. So do human annotators when curating labels for named entity recognition (NER). Such label mistakes might hurt model training and interfere comparison. In this study, we dive deep into one of the widely-adopted NER benchmark datasets, CoNLL03 NER. We are able to identify in about 5.38% test sentences, which is a significant ratio considering that state-of-the-art F1 score already around 93%. Therefore, manually correct these form cleaner set. Our re-evaluation popular models on corrected set leads more accurate assessments, compared those original More importantly, propose simple yet effective framework, CrossWeigh, handle during training. Specifically, it partitions data several folds train independent potential each fold. Then adjusts weights accordingly final model. Extensive experiments demonstrate improvements plugging various our proposed framework three datasets. All implementations available at Github repo https://github.com/ZihanWangKi/CrossWeigh."
https://openalex.org/W3105339299,https://doi.org/10.18653/v1/d16-1135,Improving Multilingual Named Entity Recognition with Wikipedia Entity Type Mapping,2016,"The state-of-the-art named entity recognition (NER) systems are statistical machine learning models that have strong generalization capability (i.e., can recognize unseen entities do not appear in training data) based on lexical and contextual information. However, such a model could still make mistakes if its features favor wrong type. In this paper, we utilize Wikipedia as an open knowledge base to improve multilingual NER systems. Central our approach is the construction of high-accuracy, high-coverage type mappings. These mappings built from weakly annotated data be extended new languages with no human annotation or language-dependent involved. Based these mappings, develop several approaches system. We evaluate performance via experiments trained for 6 languages. Experimental results show proposed effective improving accuracy entities, especially when system applied domain it little (up 18.3 F1 score improvement)."
https://openalex.org/W2986896820,https://doi.org/10.18653/v1/k19-1060,Named Entity Recognition with Partially Annotated Training Data,2019,"Supervised machine learning assumes the availability of fully-labeled data, but in many cases, such as low-resource languages, only data available is partially annotated. We study problem Named Entity Recognition (NER) with annotated training which a fraction named entities are labeled, and all other tokens, or otherwise, labeled non-entity by default. In order to train on this noisy dataset, we need distinguish between true false negatives. To end, introduce constraint-driven iterative algorithm that learns detect negatives set downweigh them, resulting weighted set. With set, NER model. evaluate our variants neural non-neural models 8 languages from several language script families, showing strong ability learn partial data. Finally, show real-world efficacy, Bengali corpus non-speakers, outperforming prior state-of-the-art over 5 points F1."
https://openalex.org/W2963654293,https://doi.org/10.18653/v1/w18-3026,Jointly Embedding Entities and Text with Distant Supervision,2018,"Learning representations for knowledge base entities and concepts is becoming increasingly important NLP applications. However, recent entity embedding methods have relied on structured resources that are expensive to create new domains corpora. We present a distantly-supervised method jointly learning embeddings of text from an unnanotated corpus, using only list mappings between surface forms. learn open-domain biomedical corpora, compare against prior rely human-annotated or large graph structure. Our capture similarity relatedness better than work, both in existing datasets Wikipedia-based dataset we release the community. Results analogy completion sense disambiguation indicate words complementary information can be effectively combined downstream use."
https://openalex.org/W2949663785,https://doi.org/10.18653/v1/p19-1510,NNE: A Dataset for Nested Named Entity Recognition in English Newswire,2019,"Named entity recognition (NER) is widely used in natural language processing applications and downstream tasks. However, most NER tools target flat annotation from popular datasets, eschewing the semantic information available nested mentions. We describe NNE—a fine-grained, named dataset over full Wall Street Journal portion of Penn Treebank (PTB). Our comprises 279,795 mentions 114 types with up to 6 layers nesting. hope public release this large for English newswire will encourage development new techniques NER."
https://openalex.org/W2963229139,https://doi.org/10.18653/v1/d17-1163,Identifying civilians killed by police with distantly supervised entity-event extraction,2017,"We propose a new, socially-impactful task for natural language processing: from news corpus, extract names of persons who have been killed by police. present newly collected police fatality which we release publicly, and model to solve this problem that uses EM-based distant supervision with logistic regression convolutional neural network classifiers. Our outperforms two off-the-shelf event extractor systems, it can suggest candidate victim in some cases faster than one the major manually-collected databases."
https://openalex.org/W2963548348,https://doi.org/10.18653/v1/n19-1117,Knowledge-Augmented Language Model and Its Application to Unsupervised Named-Entity Recognition,2019,"Traditional language models are unable to efficiently model entity names observed in text. All but the most popular named entities appear infrequently text providing insufficient context. Recent efforts have recognized that context can be generalized between share same type (e.g., \emph{person} or \emph{location}) and equipped with access an external knowledge base (KB). Our Knowledge-Augmented Language Model (KALM) continues this line of work by augmenting a traditional KB. Unlike previous methods, however, we train end-to-end predictive objective optimizing perplexity We do not require any additional information such as tags. In addition improving modeling performance, KALM learns recognize entirely unsupervised way using latent model. On Named Entity Recognition (NER) task, achieves performance comparable state-of-the-art supervised models. demonstrates (and possibly other types world knowledge) modeled successfully learning training on large corpora without information."
https://openalex.org/W2922722434,https://doi.org/10.15625/1813-9663/34/4/13161,VLSP Shared Task: Named Entity Recognition,2019,"Named entities (NE) are phrases that contain the names of persons, organizations, locations, times and quantities, monetary values, percentages, etc. Entity Recognition (NER) is task recognizing named in documents. NER an important subtask Information Extraction, which has attracted researchers all over world since 1990s. For Vietnamese language, although there exists some research projects publications on before 2016, no systematic comparison performance systems been done. In organizing committee VLSP workshop decided to launch first shared task, order get objective evaluation promote development high quality systems. As a result, dataset with morpho-syntactic NE annotations released for benchmarking At 2018, organized second time, providing bigger containing texts from various domains, but without annotation. These resources available purpose via website vlsp.org.vn/resources. this paper, we describe datasets as well results obtained these two campaigns."
https://openalex.org/W3115095335,https://doi.org/10.18653/v1/2020.coling-main.78,Exploring Cross-sentence Contexts for Named Entity Recognition with BERT,2020,"Named entity recognition (NER) is frequently addressed as a sequence classification task with each input consisting of one sentence text. It nevertheless clear that useful information for NER often found also elsewhere in Recent self-attention models like BERT can both capture long-distance relationships and represent inputs several sentences. This creates opportunities adding cross-sentence natural language processing tasks. paper presents systematic study exploring the use using five languages. We find context additional sentences to systematically increases performance. Multiple samples allows us predictions different contexts. propose straightforward method, Contextual Majority Voting (CMV), combine these demonstrate this further increase Evaluation on established datasets, including CoNLL’02 CoNLL’03 benchmarks, demonstrates our proposed approach improve state-of-the-art results English, Dutch, Finnish, achieves best reported BERT-based German, par other approaches Spanish. release all methods implemented work under open licenses."
https://openalex.org/W2920887996,https://doi.org/10.5220/0007686309150922,FoodIE: A Rule-based Named-entity Recognition Method for Food Information Extraction,2019,"The application of Natural Language Processing (NLP) methods and resources to biomedical textual data has received growing attention over the past years. Previously organized NLP-shared tasks (such as, for example, BioNLP Shared Tasks) are related extracting different entities (like genes, phenotypes, drugs, diseases, chemical entities) finding relations between them. However, best our knowledge there limited NLP that can be used information extraction food concepts. For this reason, extract from unstructured data, we propose a rule-based named-entity recognition method extraction, called FoodIE. It is comprised small number rules based on computational linguistics semantic describe entities. Experimental results evaluation performed using two datasets showed very promising achieved. proposed achieved 97% precision, 94% recall, 96% F1 score."
https://openalex.org/W2515582862,https://doi.org/10.18653/v1/w16-2913,Syntactic analyses and named entity recognition for PubMed and PubMed Central — up-to-the-minute,2016,"Although advanced text mining methods specifically adapted to the biomedical domain are continuously being developed, their applications on large scale have been scarce. One of main reasons for this is lack computational resources and workforce required processing corpora. In paper we present a publicly available resource distributing preprocessed literature including sentence splitting, tokenization, part-of-speech tagging, syntactic parses named entity recognition. The aim work support future development largescale by eliminating time consuming but necessary preprocessing steps. This covers whole PubMed Central Open Access section, currently containing 26M abstracts 1.4M full articles, constituting over 388M analyzed sentences. based fully automated pipeline, guaranteeing that distributed data always up-to-date. at https://turkunlp. github.io/pubmed_parses/."
https://openalex.org/W2963354094,https://doi.org/10.18653/v1/w18-2301,Embedding Transfer for Low-Resource Medical Named Entity Recognition: A Case Study on Patient Mobility,2018,"Functioning is gaining recognition as an important indicator of global health, but remains under-studied in medical natural language processing research. We present the first analysis automatically extracting descriptions patient mobility, using a recently-developed dataset free text electronic health records. frame task named entity (NER) problem, and investigate applicability NER techniques to mobility extraction. As corpora focused on functioning are scarce, we explore domain adaptation word embeddings for use recurrent neural network system. find that trained small in-domain corpus perform nearly well those learned from large out-of-domain corpora, yield additional improvements both precision recall. Our identifies several significant challenges including length complexity annotated entities high linguistic variability descriptions."
https://openalex.org/W2236169403,https://doi.org/10.1007/s10579-015-9330-7,Annotating patient clinical records with syntactic chunks and named entities: the Harvey Corpus,2016,"The free text notes typed by physicians during patient consultations contain valuable information for the study of disease and treatment. These are difficult to process existing natural language analysis tools since they highly telegraphic (omitting many words), spelling mistakes, inconsistencies in punctuation, non-standard word order. To support extraction classification tasks over such text, we describe a de-identified corpus notes, shallow syntactic named entity annotation scheme this kind an approach training domain specialists with no linguistic background annotate text. Finally, present statistical chunking system clinical stable learning rate good accuracy, indicating that manual is consistent tractable machine learning."
https://openalex.org/W2793058421,https://doi.org/10.3389/fdigh.2018.00002,Ensemble Named Entity Recognition (NER): Evaluating NER Tools in the Identification of Place Names in Historical Corpora,2018,"The field of Spatial Humanities has advanced substantially in the past years. identification and extraction toponyms spatial information mentioned historical text collections allowed its use innovative ways, making possible application analysis mapping these places with Geographic Information Systems. For instance, automated place name is nowadays Named Entity Recognition (NER) systems. Statistical NER methods based on supervised learning, particular, are highly successful modern datasets. However, there still major challenges to address when dealing corpora. These include language changes over time, spelling variations, transliterations, OCR errors, sources written multiple languages among others. In this article, considering a task recognition two correspondence, we report an evaluation five systems approach that combines through voting system. We found although individual performance each system was corpus dependent, ensemble combination able achieve consistent measures precision recall, outperforming Additionally, results showed not strongly dependent pre-processing translation English."
https://openalex.org/W2899463504,https://doi.org/10.18653/v1/w18-5618,In-domain Context-aware Token Embeddings Improve Biomedical Named Entity Recognition,2018,"Rapidly expanding volume of publications in the biomedical domain makes it increasingly difficult for a timely evaluation latest literature. That, along with push automated clinical reports, present opportunities effective natural language processing methods. In this study we target problem named entity recognition, where texts are processed to annotate terms that relevant studies. Terms interest include gene and protein names, cell lines types. Here report on pipeline built Embeddings from Language Models (ELMo) deep learning package (AllenNLP). We trained context-aware token embeddings dataset papers using ELMo, incorporated these LSTM-CRF model used by AllenNLP recognition. show representations improve recognition different types entities. also achieve new state art mention detection BioCreative II shared task."
https://openalex.org/W2513587312,https://doi.org/10.18653/v1/p16-2056,Bootstrapped Text-level Named Entity Recognition for Literature,2016,"We present a named entity recognition (NER) system for tagging fiction: LitNER. Relative to more traditional approaches, LitNER has two important properties: (1) it makes no use of handtagged data or gazetteers, instead bootstraps model from term clusters; and (2) leverages multiple instances the same name in text. Our experiments show substantially outperform off-the-shelf supervised NER systems."
https://openalex.org/W2740109156,https://doi.org/10.18653/v1/p17-2085,List-only Entity Linking,2017,"Traditional Entity Linking (EL) technologies rely on rich structures and properties in the target knowledge base (KB). However, many applications, KB may be as simple sparse lists of names same type (e.g., products). We call it List-only problem. Fortunately, some mentions have more cues for linking, which can used seed to bridge other uninformative entities. In this work, we select most linkable disambiguate by comparing them with rather than directly Our experiments linking seven automatically mined show promising results demonstrate effectiveness our approach."
https://openalex.org/W2887289680,https://doi.org/10.18653/v1/w18-2407,Named-Entity Tagging and Domain adaptation for Better Customized Translation,2018,"Customized translation need pay spe-cial attention to the target domain ter-minology especially named-entities for domain. Adding linguistic features neural machine (NMT) has been shown benefit in many studies. In this paper, we further demonstrate that adding named-entity (NE) feature with recognition (NER) into source language produces better NMT. Our experiments show by just including different NE classes and boundary tags, can increase BLEU score around 1 2 points using standard test sets from WMT2017. We also tags NER applying in-domain adaptation be combined improve customized translation."
https://openalex.org/W2963741336,https://doi.org/10.1609/aaai.v32i1.11507,Adversarial Learning for Chinese NER From Crowd Annotations,2018,"To quickly obtain new labeled data, we can choose crowdsourcing as an alternative way at lower cost in a short time. But exchange, crowd annotations from non-experts may be of quality than those experts. In this paper, propose approach to performing annotation learning for Chinese Named Entity Recognition (NER) make full use the noisy sequence labels multiple annotators. Inspired by adversarial learning, our uses common Bi-LSTM and private representing annotator-generic -specific information. The information is knowledge entities easily mastered crowd. Finally, build NE tagger based on LSTM-CRF model. experiments, create two data sets NER tasks domains. experimental results show that system achieves better scores strong baseline systems."
https://openalex.org/W3003335533,https://doi.org/10.1109/icdar.2019.00049,EATEN: Entity-Aware Attention for Single Shot Visual Text Extraction,2019,"Extracting entity from images is a crucial part of many OCR applications, such as recognition cards, invoices, and receipts. Most the existing works employ classical detection paradigm. This paper proposes an Entity-aware Attention Text Extraction Network called EATEN, which end-to-end trainable system to extract entities without any post-processing. In proposed framework, each parsed by its corresponding entity-aware decoder, respectively. Moreover, we innovatively introduce state transition mechanism further improves robustness extraction. consideration absence public benchmarks, construct dataset almost 0.6 million in three real-world scenarios (train ticket, passport business card), publicly available at https://github.com/beacandler/EATEN. To best our knowledge, EATEN first single shot method images. Extensive experiments on these benchmarks demonstrate state-of-the-art performance EATEN."
https://openalex.org/W3136657289,https://doi.org/10.1155/2021/6633213,ABioNER: A BERT-Based Model for Arabic Biomedical Named-Entity Recognition,2021,"The web is being loaded daily with a huge volume of data, mainly unstructured textual which increases the need for information extraction and NLP systems significantly. Named-entity recognition task key step towards efficiently understanding text data saving time effort. Being widely used language globally, English taking over most research conducted in this field, especially biomedical domain. Unlike other languages, Arabic suffers from lack resources. This work presents BERT-based model to identify named entities (specifically disease treatment entities) that investigates effectiveness pretraining monolingual BERT small-scale dataset on enhancing text. performance was compared two state-of-the-art models (namely, AraBERT multilingual cased), it outperformed both 85% F1-score."
https://openalex.org/W2250729966,https://doi.org/10.3115/v1/p15-1090,Improving Named Entity Recognition in Tweets via Detecting Non-Standard Words,2015,"Most previous work of text normalization on informal made a strong assumption that the system has already known which tokens are non-standard words (NSW) and thus need normalization. However, this is not realistic. In paper, we propose method for NSW detection. addition to information based dictionary, e.g., whether word out-ofvocabulary (OOV), leverage novel derived from results OOV help make decisions. Second, paper investigates two methods using detection named entity recognition (NER) in social media data. One adopts pipeline strategy, other uses joint decoding fashion. We also create new data set with newly added annotation beyond existing labels. This first such release it research purpose. Our experiment demonstrate effectiveness our benefit NER. proposed perform better than state-of-the-art NER system."
https://openalex.org/W2799077980,https://doi.org/10.18653/v1/p18-2109,diaNED: Time-Aware Named Entity Disambiguation for Diachronic Corpora,2018,"Named Entity Disambiguation (NED) systems perform well on news articles and other texts covering a specific time interval. However, NED quality drops when inputs span long periods like in archives or historic corpora. This paper presents the first time-aware method for that resolves ambiguities even mention contexts give only few cues. The is based computing temporal signatures entities comparing these to of input mentions. Our experiments show superior newly created diachronic corpus."
https://openalex.org/W2886440583,https://doi.org/10.18653/v1/w18-2413,Neural Machine Translation Techniques for Named Entity Transliteration,2018,"Transliterating named entities from one language into another can be approached as neural machine translation (NMT) problem, for which we use deep attentional RNN encoder-decoder models. To build a strong transliteration system, apply well-established techniques NMT, such dropout regularization, model ensembling, rescoring with right-to-left models, and back-translation. Our submission to the NEWS 2018 Shared Task on Named Entity Transliteration ranked first in several tracks."
https://openalex.org/W2988846051,https://doi.org/10.18653/v1/d19-5531,Robustness to Capitalization Errors in Named Entity Recognition,2019,"Robustness to capitalization errors is a highly desirable characteristic of named entity recognizers, yet we find standard models for the task are surprisingly brittle such noise.Existing methods improve robustness noise completely discard given orthographic information, which significantly degrades their performance on well-formed text. We propose simple alternative approach based data augmentation, allows model learn utilize or ignore information depending its usefulness in context. It achieves competitive while making negligible compromise text and improving generalization power noisy user-generated Our experiments clearly consistently validate our claim across different types machine learning models, languages, dataset sizes."
https://openalex.org/W3101260801,https://doi.org/10.1007/s10579-019-09471-7,A Finnish news corpus for named entity recognition,2019,"We present a corpus of Finnish news articles with manually prepared named entity annotation. The consists 953 (193,742 word tokens) six classes (organization, location, person, product, event, and date). are extracted from the archives Digitoday, online technology source. is available for research purposes. baseline experiments on using rule-based two deep learning systems two, in-domain out-of-domain, test sets."
https://openalex.org/W2606919896,https://doi.org/10.18517/ijaseit.7.2.1810,A Comparative Review of Machine Learning for Arabic Named Entity Recognition,2017,"Arabic Named Entity Recognition (ANER) systems aim to identify and classify entities (NEs) within text. Other important tasks in Natural Language Processing (NLP) depends on ANER such as machine translation, question-answering, information extraction, etc. In general, can be classified into three main approaches, namely, rule-based, machine-learning or hybrid systems. this paper, we focus research progress (ML) compare between linguistic resource, entity type, domain, method performance. We also highlight the challenges when processing NEs through ML"
https://openalex.org/W2970913210,https://doi.org/10.18653/v1/d19-1520,A Little Annotation does a Lot of Good: A Study in Bootstrapping Low-resource Named Entity Recognizers,2019,"Most state-of-the-art models for named entity recognition (NER) rely on the availability of large amounts labeled data, making them challenging to extend new, lower-resourced languages. However, there are now many proposed solutions this problem involving either cross-lingual transfer learning, which learns from other highly resourced languages, or active efficiently selects effective training data based model predictions. In paper, we ask question: given recent progress, and some amount human annotation, what is most method creating high-quality recognizers in under-resourced languages? Based extensive experimentation using both simulated real settle a recipe starting with transferred model, then performing targeted annotation only uncertain spans target language, minimizing annotator effort. Results demonstrate that powerful tool when very little can be annotated, but an entity-targeted strategy achieve competitive accuracy quickly, just one-tenth data."
https://openalex.org/W3104015140,https://doi.org/10.1093/bib/bbaa054,Biomedical named entity recognition and linking datasets: survey and our recent development,2020,"Natural language processing (NLP) is widely applied in biological domains to retrieve information from publications. Systems address numerous applications exist, such as biomedical named entity recognition (BNER), normalization (NEN) and protein-protein interaction extraction (PPIE). High-quality datasets can assist the development of robust reliable systems; however, due endless evolving techniques, annotations benchmark may become outdated inappropriate. In this study, we first review commonlyused BNER their potential annotation problems inconsistency low portability. Then, introduce a revised version JNLPBA dataset that solves original use state-of-the-art systems evaluate its portability different kinds literature, including biology events. Lastly, an ensembled (EBED) by extending with PubMed Central full-text paragraphs, figure captions patent abstracts. This EBED multi-task covers gene, disease chemical entities. total, it contains 85000 mentions, 25000 mentions database identifiers 5000 attribute tags. To demonstrate usage EBED, track AI CUP Biomedical Paper Analysis challenge. Availability: The available at https://iasl-btm.iis.sinica.edu.tw/BNER/Content/Re vised_JNLPBA.zip. https://iasl-btm.iis.sinica.edu.tw/BNER/Content/AICUP _EBED_dataset.rar. Contact: Email: thtsai@g.ncu.edu.tw, Tel. 886-3-4227151 ext. 35203, Fax: 886-3-422-2681 hsu@iis.sinica.edu.tw, 886-2-2788-3799 2211, 886-2-2782-4814 Supplementary information: data are Briefings Bioinformatics online."
https://openalex.org/W3104235802,https://doi.org/10.18653/v1/2020.emnlp-main.518,Entity Enhanced BERT Pre-training for Chinese NER,2020,"Character-level BERT pre-trained in Chinese suffers a limitation of lacking lexicon information, which shows effectiveness for NER. To integrate the into LMs NER, we investigate semi-supervised entity enhanced pre-training method. In particular, first extract an from relevant raw text using new-word discovery We then information Char-Entity-Transformer, augments self-attention combination character and representations. addition, classification task helps inject model parameters pre-training. The models are used NER fine-tuning. Experiments on news dataset two datasets annotated by ourselves long-text show that our method is highly effective achieves best results."
https://openalex.org/W3122921983,https://doi.org/10.48550/arxiv.2012.05426,"Empirical Analysis of Unlabeled Entity Problem in Named Entity
  Recognition",2021,"In many scenarios, named entity recognition (NER) models severely suffer from unlabeled problem, where the entities of a sentence may not be fully annotated. Through empirical studies performed on synthetic datasets, we find two causes performance degradation. One is reduction annotated and other treating as negative instances. The first cause has less impact than second one can mitigated by adopting pretraining language models. seriously misguides model in training greatly affects its performances. Based above observations, propose general approach, which almost eliminate misguidance brought entities. key idea to use sampling that, large extent, avoids NER with Experiments datasets real-world show that our robust problem surpasses prior baselines. On well-annotated competitive state-of-the-art method."
https://openalex.org/W2911748720,https://doi.org/10.18653/v1/w18-6125,Low-resource named entity recognition via multi-source projection: Not quite there yet?,2018,"Projecting linguistic annotations through word alignments is one of the most prevalent approaches to cross-lingual transfer learning. Conventional wisdom suggests that annotation projection “just works” regardless task at hand. We carefully consider multi-source for named entity recognition. Our experiment with 17 languages shows detect entities in true low-resource languages, may not be right way move forward. On a more positive note, we also uncover conditions do favor from multiple sources. argue these are infeasible under noisy constraints."
https://openalex.org/W2509805446,https://doi.org/10.18653/v1/w16-2710,Applying Neural Networks to English-Chinese Named Entity Transliteration,2016,"This paper presents the machine transliteration systems that we employ for our participation in NEWS 2016 shared task. Based on prevalent deep learning models developed general sequence processing tasks, use convolutional neural networks to extract character level information from units and stack a simple recurrent network top processing. The are applied standard runs both English Chinese tasks. Our achieve competitive results according official evaluation."
https://openalex.org/W2889938809,https://doi.org/10.18653/v1/d18-1130,Entity Tracking Improves Cloze-style Reading Comprehension,2018,"Recent work has improved on modeling for reading comprehension tasks with simple approaches such as the Attention Sum-Reader; however, automatic systems still significantly trail human performance. Analysis suggests that many of remaining hard instances are related to inability track entity-references throughout documents. This focuses these entity tracking cases two extensions: (1) additional features, and (2) training a multi-task objective. We show modifications improve performance both independently in combination, we outperform previous state art LAMBADA dataset by 8 pts, particularly difficult examples. also effectively match more complicated models named portion CBT dataset."
https://openalex.org/W3013678667,https://doi.org/10.1186/s12859-020-3375-3,Knowledge-enhanced biomedical named entity recognition and normalization: application to proteins and genes,2020,"Abstract Background Automated biomedical named entity recognition and normalization serves as the basis for many downstream applications in information management. However, this task is challenging due to name variations ambiguity. A may have multiple variants a variant could denote several different identifiers. Results To remedy above issues, we present novel knowledge-enhanced system protein/gene (PNER) (PNEN). On one hand, large amount of knowledge extracted from bases used recognize more variants. other structural entities encoded identifier (ID) embeddings, which are then better normalization. Moreover, deep contextualized word representations generated by pre-trained language models also incorporated into our modeling multi-sense entities. Experimental results on BioCreative VI Bio-ID corpus show that proposed achieves 0.871 F 1-score PNER 0.445 PNEN, respectively, leading new state-of-the-art performance. Conclusions We propose combines both representations. Comparison beneficial PNEN can be well combined with further improvement."
https://openalex.org/W3035526303,https://doi.org/10.18653/v1/2020.acl-main.612,Improving Entity Linking through Semantic Reinforced Entity Embeddings,2020,"Entity embeddings, which represent different aspects of each entity with a single vector like word are key component neural linking models. Existing embeddings learned from canonical Wikipedia articles and local contexts surrounding target entities. Such effective, but too distinctive for models to learn contextual commonality. We propose simple yet effective method, FGS2EE, inject fine-grained semantic information into reduce the distinctiveness facilitate learning FGS2EE first uses type words generate then combines them existing through linear aggregation. Extensive experiments show effectiveness such embeddings. Based on our we achieved new sate-of-the-art performance linking."
https://openalex.org/W3100180738,https://doi.org/10.18653/v1/2020.emnlp-main.514,Coarse-to-Fine Pre-training for Named Entity Recognition,2020,"More recently, Named Entity Recognition hasachieved great advances aided by pre-trainingapproaches such as BERT. However, currentpre-training techniques focus on building lan-guage modeling objectives to learn a gen-eral representation, ignoring the named entity-related knowledge. To this end, we proposea NER-specific pre-training framework in-ject coarse-to-fine automatically mined entityknowledge into pre-trained models. Specifi-cally, first warm-up model via an en-tity span identification task training it withWikipedia anchors, which can be deemed asgeneral-typed entities. Then leverage thegazetteer-based distant supervision strategy totrain extract coarse-grained typedentities. Finally, devise self-supervisedauxiliary mine fine-grained namedentity knowledge clustering.Empiricalstudies three public NER datasets demon-strate that our achieves significantimprovements against several base-lines, establishing new state-of-the-art per-formance benchmarks. Besides, weshow gains promising re-sults without using human-labeled trainingdata, demonstrating its effectiveness in label-few and low-resource scenarios."
https://openalex.org/W2890887452,https://doi.org/10.18653/v1/d18-1345,On the Strength of Character Language Models for Multilingual Named Entity Recognition,2018,"Character-level patterns have been widely used as features in English Named Entity Recognition (NER) systems. However, to date there has no direct investigation of the inherent differences between name and nonname tokens text, nor whether this property holds across multiple languages. This paper analyzes capabilities corpus-agnostic Language Models (CLMs) binary task distinguishing from non-name tokens. We demonstrate that CLMs provide a simple powerful model for capturing these differences, identifying named entity diverse set languages at close performance full NER Moreover, by adding very CLM-based we can significantly improve an off-the-shelf system"
https://openalex.org/W2899206203,https://doi.org/10.18653/v1/w18-5622,Evaluation of a Sequence Tagging Tool for Biomedical Texts,2018,"Many applications in biomedical natural language processing rely on sequence tagging as an initial step to perform more complex analysis. To support text analysis the domain, we introduce Yet Another SEquence Tagger (YASET), open-source multi purpose tagger that implements state-of-the-art deep learning algorithms for tagging. Herein, evaluate YASET part-of-speech and named entity recognition a variety of genres including articles from literature English clinical narratives French. further characterize performance, report distributions over 30 runs different sizes training datasets. provides performance CoNLL 2003 NER dataset (F1=0.87), MEDPOST corpus (F1=0.97), MERLoT (F1=0.99) NCBI disease (F1=0.81). We believe is versatile efficient tool can be used texts."
https://openalex.org/W2951820126,https://doi.org/10.18653/v1/p19-1014,A Joint Named-Entity Recognizer for Heterogeneous Tag-sets Using a Tag Hierarchy,2019,"We study a variant of domain adaptation for named-entity recognition where multiple, heterogeneously tagged training sets are available. Furthermore, the test tag-set is not identical to any individual tag-set. Yet, relations between all tags provided in tag hierarchy, covering as combination tags. This setting occurs when various datasets created using different annotation schemes. also case extending with new by annotating only dataset. propose use given hierarchy jointly learn neural network that shares its tagging layer among tag-sets. compare this model combining independent models and based on multitasking approach. Our experiments show benefit tag-hierarchy model, especially facing non-trivial consolidation"
https://openalex.org/W3034263272,https://doi.org/10.18653/v1/2020.acl-main.722,Soft Gazetteers for Low-Resource Named Entity Recognition,2020,"Traditional named entity recognition models use gazetteers (lists of entities) as features to improve performance. Although modern neural network do not require such hand-crafted for strong performance, recent work has demonstrated their utility on English data. However, designing low-resource languages is challenging, because exhaustive exist in these languages. To address this problem, we propose a method ``soft gazetteers'' that incorporates ubiquitously available information from knowledge bases, Wikipedia, into through cross-lingual linking. Our experiments four show an average improvement 4 points F1 score."
https://openalex.org/W3048090083,https://doi.org/10.1109/access.2020.3015056,Improving Distantly-Supervised Named Entity Recognition for Traditional Chinese Medicine Text via a Novel Back-Labeling Approach,2020,"Recent advances in deep neural networks (DNNs) have enabled us to achieve reliable named entity recognition (NER) models without handcrafting features. However, these are also some obstacles imposed by using those machine learning methods, need of a large amount manually labeled data. To avoid such limitations, we could replace human annotation with distant supervision, however there remain technical challenge on the error label issue caused ignoring entities that not included vocabulary, which should be addressed effective NER model. Then, propose novel back-labeling approach and integrate it into tagging scheme, especially, apply this scheme handle task traditional Chinese medicine (TCM) field. In addition, discuss how use supervision methods better performance We conduct experiments verify our can effectively improve basis supervision."
https://openalex.org/W2791951321,https://doi.org/10.1093/bioinformatics/bty152,Exploiting and assessing multi-source data for supervised biomedical named entity recognition,2018,"Recognition of biomedical entities from scientific text is a critical component natural language processing and automated information extraction platforms. Modern named entity recognition approaches rely heavily on supervised machine learning techniques, which are critically dependent annotated training corpora. These have been shown to perform well when trained tested the same source. However, in such scenario, performance evaluation these models may be optimistic, as not necessarily generalize independent corpora, resulting potential non-optimal for large-scale tagging widely diverse articles databases PubMed.Here we aggregated published corpora biomolecular (such genes, RNA, proteins, variants, drugs metabolites), identified class overlap performed leave-corpus-out cross validation strategy test efficiency existing models. We demonstrate that accuracies individual decrease substantially classes This behavior possibly due limited generalizability entity-class-related features captured by (model 'overtraining') investigated further at orthographic level, annotation standard differences. show combined use multi-source results overall more generalizable recognition, while achieving comparable performance. By performing learning-curve-based power analysis often quantity data.Compiled primary secondary sources available on: https://github.com/dterg/biomedical_corpora/wiki https://bitbucket.org/iAnalytica/bioner.Supplementary data Bioinformatics online."
https://openalex.org/W2887660679,https://doi.org/10.18653/v1/w18-2409,Report of NEWS 2018 Named Entity Transliteration Shared Task,2018,"This report presents the results from Named Entity Transliteration Shared Task conducted as part of The Seventh Entities Workshop (NEWS 2018) held at ACL 2018 in Melbourne, Australia. Similar to previous editions NEWS, featured 19 tasks on proper name transliteration, including 13 different languages and two Japanese scripts. A total 6 teams 8 institutions participated evaluation, submitting 424 runs, involving transliteration methodologies. Four performance metrics were used evaluation results. NEWS shared task machine has successfully achieved its objectives by providing a common ground for research community conduct comparative evaluations state-of-the-art technologies that will benefit future development this area."
https://openalex.org/W3101231927,https://doi.org/10.18653/v1/2020.emnlp-main.723,Named Entity Recognition Only from Word Embeddings,2020,"Deep neural network models have helped named entity recognition achieve amazing performance without handcrafting features. However, existing systems require large amounts of human annotated training data. Efforts been made to replace annotations with external knowledge (e.g., NE dictionary, part-of-speech tags), while it is another challenge obtain such effective resources. In this work, we propose a fully unsupervised model which only needs take informative clues from pre-trained word embeddings.We first apply Gaussian Hidden Markov Model and Autoencoding Mixture on embeddings for span detection type prediction, then further design an instance selector based reinforcement learning distinguish positive sentences noisy refine these coarse-grained through networks. Extensive experiments two CoNLL benchmark NER datasets (CoNLL-2003 English dataset CoNLL-2002 Spanish dataset) demonstrate that our proposed light achieves remarkable using any lexicon or corpus."
https://openalex.org/W2789227036,https://doi.org/10.1145/3178876.3186074,Leveraging Fine-Grained Wikipedia Categories for Entity Search,2018,"Ad-hoc entity search, which is to retrieve a ranked list of relevant entities in response query natural language question, has been widely studied. It shown that category matching entities, especially when fine-grained types/categories, critical the performance search. However, potentials Wikipedia categories, not well exploited by existing studies. Based on observation how people describe specific type, we propose headword-and-modifier model deeply interpret both queries and types/categories. Probabilistic generative models are designed effectively estimate relevance headwords modifiers as pattern-based problem, taking type taxonomy an important input address ad-hoc representations concepts/entities queries. Extensive experimental results three widely-used test sets: INEX-XER 2009, SemSearch-LS TREC-Entity, show our method achieves significant improvement search over state-of-the-art methods."
https://openalex.org/W2998566943,https://doi.org/10.1609/aaai.v34i05.6234,Fine-Grained Named Entity Typing over Distantly Supervised Data Based on Refined Representations,2020,"Fine-Grained Named Entity Typing (FG-NET) is a key component in Natural Language Processing (NLP). It aims at classifying an entity mention into wide range of types. Due to large number types, distant supervision used collect training data for this task, which noisily assigns type labels mentions irrespective the context. In order alleviate noisy labels, existing approaches on FGNET analyze entirely independent each other and assign solely based sentence-specific This inadequate highly overlapping as it hinders information passing across sentence boundaries. For this, we propose edge-weighted attentive graph convolution network that refines representations by attending over corpus-level contextual clues prior end classification. Experimental evaluation shows proposed model outperforms research relative score upto 10.2% 8.3% macro f1 micro respectively."
https://openalex.org/W3037636427,https://doi.org/10.18653/v1/2020.repl4nlp-1.24,What’s in a Name? Are BERT Named Entity Representations just as Good for any other Name?,2020,"We evaluate named entity representations of BERT-based NLP models by investigating their robustness to replacements from the same typed class in input. highlight that on several tasks while such perturbations are natural, state art trained surprisingly brittle. The brittleness continues even with recent entity-aware BERT models. also try discern cause this non-robustness, considering factors as tokenization and frequency occurrence. Then we provide a simple method ensembles predictions multiple jointly modeling uncertainty type annotations label predictions. Experiments three shows our enhances increases accuracy both natural adversarial datasets."
https://openalex.org/W2547066600,https://doi.org/10.1007/978-3-319-49004-5_19,Combining Textual and Graph-Based Features for Named Entity Disambiguation Using Undirected Probabilistic Graphical Models,2016,"Named Entity Disambiguation NED is the task of disambiguating named entities in a natural language text by linking them to their corresponding knowledge base such as DBpedia, which are already recognized. It an important step transforming unstructured into structured knowledge. Previous work on this has proven strong impact graph-based methods PageRank entity disambiguation. Other approaches rely distributional similarity between article and textual description candidate entity. However, combined these different feature groups not been explored sufficient extent. In paper, we present novel approach that exploits undirected probabilistic model combine types features for Capitalizing Markov Chain Monte Carlo sampling, our capable exploiting complementary strengths both features. We analyze combination evaluation GERBIL benchmark, compares favourably current state-of-the-art 8 out 14 data sets."
https://openalex.org/W2890060418,https://doi.org/10.1007/978-3-030-00671-6_8,TSE-NER: An Iterative Approach for Long-Tail Entity Extraction in Scientific Publications,2018,"Named Entity Recognition and Typing (NER/NET) is a challenging task, especially with long-tail entities such as the ones found in scientific publications. These (e.g. “WebKB”,“StatSnowball”) are rare, often relevant only specific knowledge domains, yet important for retrieval exploration purposes. State-of-the-art NER approaches employ supervised machine learning models, trained on expensive type-labeled data laboriously produced by human annotators. A common workaround generation of labeled training from bases; this approach not suitable entity types that are, definition, scarcely represented KBs. This paper presents an iterative NET classifiers publications relies minimal input, namely small seed set instances targeted type. We introduce different strategies extraction, semantic expansion, result filtering. evaluate our publications, focusing Datasets, Methods computer science Proteins biomedical"
https://openalex.org/W2950659199,https://doi.org/10.1007/978-3-030-22734-0_29,Creating Training Data for Scientific Named Entity Recognition with Minimal Human Effort,2019,"Scientific Named Entity Referent Extraction is often more complicated than traditional Recognition (NER). For example, in polymer science, chemical structure may be encoded a variety of nonstandard naming conventions, and authors refer to polymers with conventional names, commonly used labels (in lieu longer names), synonyms, acronyms. As result, accurate scientific NER methods are based on task-specific rules, which difficult develop maintain, not easily generalized other tasks fields. Machine learning models require substantial expert-annotated data for training. Here we propose polyNER: semi-automated system efficient identification entities text. PolyNER applies word embedding generate entity-rich corpora productive expert labeling, then uses the resulting labeled bootstrap context-based vector classifier. Evaluation materials science publications shows that polyNER approach enables improved precision or recall relative state-of-the-art entity extraction at dramatically lower cost: it required just two hours time, rather extensive expensive rule engineering, achieve result. This result highlights potential human-computer partnership constructing domain-specific systems."
https://openalex.org/W2989311894,https://doi.org/10.18653/v1/k19-1048,Learning a Unified Named Entity Tagger from Multiple Partially Annotated Corpora for Efficient Adaptation,2019,"Named entity recognition (NER) identifies typed mentions in raw text. While the task is well-established, there no universally used tagset: often, datasets are annotated for use downstream applications and accordingly only cover a small set of types relevant to particular task. For instance, biomedical domain, one corpus might annotate genes, another chemicals, diseases—despite texts each containing references all three entities. In this paper, we propose deep structured model integrate these “partially annotated” jointly identify appearing training corpora. By leveraging multiple datasets, can learn robust input representations; by building joint model, it avoids potential conflicts caused combining several models’ predictions at test time. Experiments show that proposed significantly outperforms strong multi-task learning baselines when on multiple, partially testing contain tags from more than"
https://openalex.org/W3095918555,https://doi.org/10.21437/interspeech.2020-2482,End-to-End Named Entity Recognition from English Speech,2020,"Named entity recognition (NER) from text has been a widely studied problem and usually extracts semantic information text. Until now, NER speech is mostly in two-step pipeline process that includes first applying an automatic (ASR) system on audio sample then passing the predicted transcript to tagger. In such cases, error does not propagate one step another as both tasks are optimized end-to-end (E2E) fashion. Recent studies confirm integrated approaches (e.g., E2E ASR) outperform sequential ones phoneme based ASR). this paper, we introduce publicly available annotated dataset for English present approach, which jointly optimizes ASR tagger components. Experimental results show proposed approach outperforms classical approach. We also discuss how can be used handle out of vocabulary (OOV) words system."
https://openalex.org/W3101778449,https://doi.org/10.1007/978-3-030-20912-4_4,Combining Neural and Knowledge-Based Approaches to Named Entity Recognition in Polish,2019,"Named entity recognition (NER) is one of the tasks in natural language processing that can greatly benefit from use external knowledge sources. We propose a named framework composed knowledge-based feature extractors and deep learning model including contextual word embeddings, long short-term memory (LSTM) layers conditional random fields (CRF) inference layer. an linking module to integrate our system with Wikipedia. The combination effective neural architecture resources allows us obtain state-of-the-art results on Polish proper names. evaluate data PolEval 2018 NER challenge which it outperforms other methods, reducing error rate by 22.4% compared winning solution. Our work shows combining base more recognizing entities than using alone."
https://openalex.org/W3153386185,https://doi.org/10.18653/v1/2021.eacl-main.59,TDMSci: A Specialized Corpus for Scientific Literature Entity Tagging of Tasks Datasets and Metrics,2021,"Tasks, Datasets and Evaluation Metrics are important concepts for understanding experimental scientific papers. However, previous work on information extraction literature mainly focuses the abstracts only, does not treat datasets as a separate type of entity (Zadeh Schumann, 2016; Luan et al., 2018). In this paper, we present new corpus that contains domain expert annotations Task (T), Dataset (D), Metric (M) entities 2,000 sentences extracted from NLP We report experiment results TDM using simple data augmentation strategy apply our tagger to around 30,000 papers ACL Anthology. The is made publicly available community fostering research publication summarization (Erera 2019) knowledge discovery."
https://openalex.org/W2171876133,https://doi.org/10.3115/v1/p15-4006,NEED4Tweet: A Twitterbot for Tweets Named Entity Extraction and Disambiguation,2015,"In this demo paper, we present NEED4Tweet, a Twitterbot for named entity extraction (NEE) and disambiguation (NED) Tweets. The straightforward application of state-of-the-art approaches on informal text widely used in Tweets, typically results significantly degraded performance due to the lack formal structure; sufficient context required; seldom entities involved. introduce novel framework that copes with introduced challenges. We rely contextual semantic features more than syntactic which are less informative. believe can help improve process. This mimics way humans understand language."
https://openalex.org/W2510314271,https://doi.org/10.18653/v1/w16-2706,Constructing a Japanese Basic Named Entity Corpus of Various Genres,2016,"This paper introduces a Japanese Named Entity (NE) corpus of various genres. We annotated 136 documents in the Balanced Corpus Contemporary Written (BCCWJ) with eight types NE tags defined by Information Retrieval and Extraction Exercise. The consists six genres such as blogs, magazines, white papers, so on, contains 2,464 total. can be reproduced BCCWJ tagging information obtained from https://sites.google.com/ site/projectnextnlpne/en/ ."
https://openalex.org/W2619791602,https://doi.org/10.18517/ijaseit.7.3.1811,Arabic Rule-Based Named Entity Recognition Systems Progress and Challenges,2017,"Rule-based approaches are using human-made rules to extract Named Entities (NEs), it is one of the most famous ways NE as well Machine Learning.  The term Entity Recognition (NER) defined a task determined indicate personal names, locations, organizations and many other entities. In Arabic language, Big Data challenges make NER develops rapidly extracts useful information from texts. The current paper sheds some light on research progress in rule-based via diagnostic comparison among linguistic resource, entity type, domain, performance. We also highlight processing NEs through systems. It expected that good performance will be effective modern fields like semantic web searching, question answering, machine translation, retrieval, abstracting"
https://openalex.org/W2775451169,https://doi.org/10.26615/978-954-452-049-6_066,Bootstrapping a Romanian Corpus for Medical Named Entity Recognition,2017,"Named Entity Recognition (NER) is an important component of natural language processing (NLP), with applicability in biomedical domain, enabling knowledge-discovery from medical texts. Due to the fact that for Romanian there are only a few linguistic resources specific it was created sub-corpus this domain. In paper we present newly developed medical-domain NER, which valuable asset field text processing. We provide description sub-corpus, informative statistics about data-composition and evaluate automatic NER tool on resource."
https://openalex.org/W2602535590,https://doi.org/10.1142/s2425038416300202,Entity linking for tweets,2017,"Named Entity Linking (NEL) is the task of semantically annotating entity mentions in a portion text with links to knowledge base. The automatic annotation, which requires recognition and disambiguation mention, usually exploits contextual clues like context usage coherence respect other entities. In Twitter, limits 140 characters originates very short noisy messages that pose new challenges linking task. We propose an overview NEL methods focusing on approaches specifically developed deal messages, tweets. fundamental for extraction annotation concepts tweets, necessary making Twitter’s huge amount interconnected user-generated contents machine readable enable intelligent information access."
https://openalex.org/W2740074898,https://doi.org/10.18653/v1/w17-1414,Language-Independent Named Entity Analysis Using Parallel Projection and Rule-Based Disambiguation,2017,"The 2017 shared task at the Balto-Slavic NLP workshop requires identifying coarse-grained named entities in seven languages, each entity’s base form, and clustering name mentions across multilingual set of documents. fact that no training data is provided to systems for building supervised classifiers further adds complexity. To complete we first use publicly available parallel texts project entity recognition capability from English evaluation language. We ignore entirely subtask non-inflected forms names. Finally, create cross-document identifiers by using a procedure-based approach."
https://openalex.org/W2963461172,https://doi.org/10.1109/ispras.2018.00015,pioNER: Datasets and Baselines for Armenian Named Entity Recognition,2018,"In this work, we tackle the problem of Armenian named entity recognition, providing silver- and gold-standard datasets as well establishing baseline results on popular models. We present a 163000-token corpus automatically generated annotated from Wikipedia, another 53400-token news sentences with manual annotation people, organization location entities. The corpora were used to train evaluate several recognition Alongside datasets, release 50-, 100-, 200-, 300-dimensional GloVe word embeddings trained collection texts news, blogs, encyclopedia."
https://openalex.org/W3046245238,https://doi.org/10.1145/3383583.3398597,Linking Named Entities across Languages using Multilingual Word Embeddings,2020,"Digital libraries are online collections of digital objects that can include text, images, audio, or videos in several languages. It has long been observed named entities (NEs) key to the access library portals as they contained most user queries. However, NEs have different spellings for each language which reduces performance queries retrieve documents across Cross-lingual entity linking (XEL) connects from a source external knowledge bases another (target) language. The XEL task is especially challenging due diversity languages and contexts. This paper describes an system applied evaluated with pairs including English various low-resourced linguistic families such Croatian, Finnish, Estonian, Slovenian. We tested this approach analyze link them version Wikipedia. present resulting study analysis challenges involved case degraded libraries. Further works will make extensive impact our on OCRed documents."
https://openalex.org/W3153718466,https://doi.org/10.1145/3404835.3463255,"A Multilingual Dataset for Named Entity Recognition, Entity Linking and Stance Detection in Historical Newspapers",2021,"Named entity processing over historical texts is more and being used due to the massive documents archives stored in digital libraries. However, poor annotated resources of nature, information extraction performances fall behind those on contemporary texts. In this paper, we introduce development NewsEye resource, a multilingual dataset for named recognition linking enriched with stances towards entities. The comprised diachronic newspaper material published between 1850 1950 French, German, Finnish, Swedish. Such resource essential context developing evaluating systems. It evenly allows enhancing existing approaches which enables adequate efficient semantic indexing cultural heritage collections."
https://openalex.org/W2251215683,https://doi.org/10.18653/v1/w15-3910,A Hybrid Transliteration Model for Chinese/English Named Entities —BJTU-NLP Report for the 5th Named Entities Workshop,2015,"This paper presents our system (BJTU-NLP system) for the NEWS2015 evaluation task of Chinese-to-English and English-to-Chinese named entity transliteration. Our adopts a hybrid machine transliteration approach, which combines several features. To further improve result, we adopt external data extracted from wikipeda to expand training set. In addition, pre-processing post-processing rules are utilized performance. The final performance on test corpus shows that achieves comparable results with other state-of-the-art systems."
https://openalex.org/W2798633885,https://doi.org/10.1145/3184558.3186916,Hierarchical Type Constrained Topic Entity Detection for Knowledge Base Question Answering,2018,"Topic entity detection is to find out the main asked in a question, which significant question answering. Traditional methods ignore information of entities, especially types and their hierarchical structures, restricting performance. To take full advantage Knowledge Base(KB) detect topic entities correctly, we propose deep neural model leverage type hierarchy relations KB. Experimental results demonstrate effectiveness proposed method."
https://openalex.org/W3163109966,https://doi.org/10.1145/3404835.3463258,Conversational Entity Linking: Problem Definition and Datasets,2021,"Machine understanding of user utterances in conversational systems is utmost importance for enabling engaging and meaningful conversations with users. Entity Linking (EL) one the means text understanding, proven efficacy various downstream tasks information retrieval. In this paper, we study entity linking systems. To develop a better what EL setting entails, analyze large number dialogues from existing datasets annotate references to concepts, named entities, personal entities using crowdsourcing. Based on annotated dialogues, identify main characteristics linking. Further, report performance traditional our Conversational dataset, ConEL, present an extension these methods fit setting. The resources released paper include datasets, detailed descriptions crowdsourcing setups, as well annotations produced by These new allow investigation how role different that documents or isolated short like queries tweets, complement datasets."
https://openalex.org/W3170348785,https://doi.org/10.18653/v1/2021.naacl-industry.25,Noise Robust Named Entity Understanding for Voice Assistants,2021,"Named Entity Recognition (NER) and Linking (EL) play an essential role in voice assistant interaction, but are challenging due to the special difficulties associated with spoken user queries. In this paper, we propose a novel architecture that jointly solves NER EL tasks by combining them joint reranking module. We show our proposed framework improves accuracy up 3.13% 3.6% F1 score. The features used also lead better accuracies other natural language understanding tasks, such as domain classification semantic parsing."
https://openalex.org/W3196696529,https://doi.org/10.1162/tacl_a_00438,Planning with Learned Entity Prompts for Abstractive Summarization,2021,"Abstract We introduce a simple but flexible mechanism to learn an intermediate plan ground the generation of abstractive summaries. Specifically, we prepend (or prompt) target summaries with entity chains—ordered sequences entities mentioned in summary. Transformer-based sequence-to-sequence models are then trained generate chain and continue generating summary conditioned on input. experimented both pretraining finetuning this content planning objective. When evaluated CNN/DailyMail, XSum, SAMSum, BillSum, demonstrate empirically that grounded objective improves specificity for all datasets, achieves state-of-the-art performance XSum SAMSum terms rouge. Moreover, chains provides control hallucinations By prompting decoder modified drops hallucinated entities, outperform approaches faithfulness when automatically by humans."
https://openalex.org/W1641800451,https://doi.org/10.2991/isci-15.2015.266,The Technical Analyses of Named Entity Translation,2015,"There are three methods: rule-based method, statistical method and web mining for named entity translation. The did not achieve satisfactory results. High-quality translation equivalents can be obtained from parallel corpora a prerequisite is the availability of large scale annotated corpora. comparable easier to obtain than But extraction achieves lower accuracy that Web acquire high-frequency entities it difficult translate low-frequency entities."
https://openalex.org/W2338846265,https://doi.org/10.5121/ijist.2016.6202,Study of Named Entity Recognition for Indian Languages,2016,"Named Entity Recognition is a prior task in Natural Language Processing. sub of information extraction and it identifies classifies proper nouns to its predefined categories such as person, location, organization, time, date etc. In this document the major focus given on NER approaches work done till now for various languages identify Entities been discussed. Author have comparative study recognize named entity identified that CRF approach proven best Indian entity."
https://openalex.org/W2511406623,https://doi.org/10.18653/v1/p16-3021,Building a Corpus for Japanese Wikification with Fine-Grained Entity Classes,2016,"In this research, we build a Wikification corpus for advancing Japanese Entity Linking. This consists of 340 newspaper articles with 25,675 entity mentions. All mentions are labeled by fine-grained semantic classes (200 classes), and 19,121 were successfully linked to Wikipedia articles. Even the classes, found it hard define target linking annotations utilize improve accuracy linking."
https://openalex.org/W2551978734,https://doi.org/10.5220/0006032401500157,Grammar and Dictionary based Named-entity Linking for Knowledge Extraction of Evidence-based Dietary Recommendations,2016,"In order to help people follow the new knowledge about healthy diet that comes rapidly each day with published scientific reports, a grammar and dictionary based named-entity linking method is presented can be used for extraction of evidence-based dietary recommendations. The consists two phases. first one mix entity detection determination set candidates entity, second candidate selection. We evaluate our using corpus from recommendations in sentence provided by World Health Organization U.S. National Library Medicine. 50 10 sentences are not related For 47 out proposed extract all useful knowledge, remaining 3 only information missing. Due recommendation does any entities, as expected."
https://openalex.org/W2557632639,https://doi.org/10.1186/s40649-016-0032-0,Text normalization for named entity recognition in Vietnamese tweets,2016,"Named entity recognition (NER) is a task of detecting named entities in documents and categorizing them to predefined classes, such as person, location, organization. This paper focuses on tweets posted Twitter. Since are noisy, irregular, brief, include acronyms spelling errors, NER those challenging task. Many approaches have been proposed deal with this problem written English, Germany, Chinese, etc., but none for Vietnamese tweets.We propose method that normalizes tweet before taking an input learning model tweets. The normalization step detects errors corrects using improved Dice's coefficient or n-grams. A Support Vector Machine algorithm employed learn classifier six different types features.We train our training set consisting more than 40,000 evaluate it testing 3,186 entities. experimental results showed system achieves state-of-the-art performance F1 score 82.13%."
https://openalex.org/W2589080577,https://doi.org/10.4312/slo2.0.2016.1.20-41,Tagging Named Entities in Croatian Tweets,2017,"Named entity extraction tools designed for recognizing named entities in texts written standard language (e.g., news stories or legal texts) have been shown to be inadequate user-generated textual content tweets, forum posts). In this work, we propose a supervised approach recognition and classification Croatian tweets. We compare two sequence labelling models: hidden Markov model (HMM) conditional random fields (CRF). Our experiments reveal that CRF is the best task, achieving very good performance of over 87% micro-averaged F1 score. analyse contributions different feature groups influence training set size on model."
https://openalex.org/W2910090829,https://doi.org/10.48550/arxiv.1901.04787,"A Tweet Dataset Annotated for Named Entity Recognition and Stance
  Detection",2019,"Annotated datasets in different domains are critical for many supervised learning-based solutions to related problems and the evaluation of proposed solutions. Topics natural language processing (NLP) similarly require annotated be used such purposes. In this paper, we target at two NLP problems, named entity recognition stance detection, present details a tweet dataset Turkish information. Within course current study, both annotations included tweets made publicly available, although previously has been shared with only. We believe that will useful uncovering possible relationships between detection tweets."
https://openalex.org/W3101513017,https://doi.org/10.18653/v1/2020.clinicalnlp-1.15,MeDAL: Medical Abbreviation Disambiguation Dataset for Natural Language Understanding Pretraining,2020,"One of the biggest challenges that prohibit use many current NLP methods in clinical settings is availability public datasets. In this work, we present MeDAL, a large medical text dataset curated for abbreviation disambiguation, designed natural language understanding pre-training domain. We pre-trained several models common architectures on and empirically showed such leads to improved performance convergence speed when fine-tuning downstream tasks."
https://openalex.org/W3106020419,https://doi.org/10.1109/jcsse.2019.8864166,Information Extraction based on Named Entity for Tourism Corpus,2019,"Tourism information is scattered around nowadays. To search for the information, it usually time consuming to browse through results from engine, select and view details of each accommodation. In this paper, we present a methodology extract particular full text returned engine facilitate users. Then, users can specifically look desired relevant information. The approach be used same task in other domains. main steps are 1) building training data 2) recognition model. First, tourism gathered vocabularies built. raw corpus train creating vocabulary embedding. Also, annotated data. process named entity annotation presented. model given type From experiments, hotel description, entity,i.e, name, location, facility. extracted further stored as structured e.g., ontology format, future querying inference. automatic identification, based on machine learning, yields error ranging 8%-25%."
https://openalex.org/W3120588017,https://doi.org/10.1016/j.ipm.2020.102479,Reddit entity linking dataset,2021,"We introduce and make publicly available an entity linking dataset from Reddit that contains 17,316 linked entities, each annotated by three human annotators then grouped into Gold, Silver, Bronze to indicate inter-annotator agreement. analyze the different errors disagreements made suggest types of corrections raw data. Finally, we tested existing models are trained tuned on text non-social media datasets. find that, although these perform very well their original datasets, they poorly this social dataset. also show majority can be attributed poor performance mention detection subtask. These results need for better applied enormous amount text."
https://openalex.org/W3121433727,https://doi.org/10.1109/bibm49941.2020.9313126,Fine-Grained Named Entity Recognition with Distant Supervision in COVID-19 Literature,2020,"Biomedical named entity recognition (BioNER) is a fundamental step for mining COVID-19 literature. Existing BioNER datasets cover few common coarse-grained types (e.g., genes, chemicals, and diseases), which cannot be used to recognize highly domain-specific animal models of diseases) or emerging ones coronaviruses) studies. We present CORD-NER, fine-grained recognized dataset literature (up until May 19, 2020). CORD-NER contains over 12 million sentences annotated via distant supervision. Also included in are 2,000 manually-curated as test set performance evaluation. covers 75 types. In addition the biomedical types, it new specifically related studies, such coronaviruses, viral proteins, evolution, immune responses. The dictionaries these collected from existing knowledge bases human-input seed sets. further DISTNER, distantly supervised NER model that relies on massive unlabeled corpus collection annotate corpus. DISTNER provides benchmark future research."
https://openalex.org/W3125025218,https://doi.org/10.1155/2021/6610965,A Novel Chinese Entity Relationship Extraction Method Based on the Bidirectional Maximum Entropy Markov Model,2021,"To identify relationships among entities in natural language texts, extraction of entity technically provides a fundamental support for knowledge graph, intelligent information retrieval, and semantic analysis, promotes the construction bases, improves efficiency searching analysis. Traditional methods relationship extraction, either those proposed at earlier times or based on traditional machine learning deep learning, have focused keeping their own silos: extracting are conducted steps before obtaining mappings. address this problem, novel Chinese method is paper. Firstly, triple treated as an relation chain can predict its corresponding after relationship. Secondly, Joint Extraction Entity Mentions Relations model Bidirectional Long Short-Term Memory Maximum Entropy Markov Model (Bi-MEMM). Experimental results indicate that achieve precision 79.2% which much higher than models."
https://openalex.org/W3172033172,https://doi.org/10.18653/v1/2021.smm4h-1.14,Neural Text Classification and Stacked Heterogeneous Embeddings for Named Entity Recognition in SMM4H 2021,2021,"This paper presents our findings from participating in the SMM4H Shared Task 2021. We addressed Named Entity Recognition (NER) and Text Classification. To address NER we explored BiLSTM-CRF with Stacked Heterogeneous embeddings linguistic features. investigated various machine learning algorithms (logistic regression, SVM Neural Networks) to text classification. Our proposed approaches can be generalized different languages have shown its effectiveness for English Spanish. classification submissions achieved competitive performance F1-score of 0.46 0.90 on ADE Classification (Task 1a) Profession 7a) respectively. In case NER, scored 0.50 0.82 Span Detection 1b) span detection 7b)"
https://openalex.org/W3199520873,https://doi.org/10.18653/v1/2021.emnlp-main.302,RockNER: A Simple Method to Create Adversarial Examples for Evaluating the Robustness of Named Entity Recognition Models,2021,"To audit the robustness of named entity recognition (NER) models, we propose RockNER, a simple yet effective method to create natural adversarial examples. Specifically, at level, replace target entities with other same semantic class in Wikidata; context use pre-trained language models (e.g., BERT) generate word substitutions. Together, two levels attack produce examples that result shifted distribution from training data on which our have been trained. We apply proposed OntoNotes dataset and new benchmark OntoRock for evaluating existing NER via systematic evaluation protocol. Our experiments analysis reveal even best model has significant performance drop, these seem memorize in-domain patterns instead reasoning context. work also studies effects few augmentation methods improve models."
https://openalex.org/W2250219232,https://doi.org/10.18653/v1/w15-4309,Data Adaptation for Named Entity Recognition on Tweets with Features-Rich CRF,2015,"This article describes our CRF named entity extractor for Twitter data. We first discuss some specificities of the task, with an example found in training Then we present how built model, especially way features were defined. The results these experiments are given. also tested model dev 2015 data and describe procedure have used to adapt older available this shared task. Our final task discussed."
https://openalex.org/W2280767840,https://doi.org/10.5121/ijnlc.2015.4501,Semi-Supervised Bootstrapping Approach for Named Entity Recognition,2015,"The aim of Named Entity Recognition (NER) is to identify references named entities in unstructured documents, and classify them into pre-defined semantic categories. NER often aids from added background knowledge the form gazetteers. However using such a collection does not deal with name variants cannot resolve ambiguities associated identifying context associating predefined We present semi-supervised approach that starts small set training data. Using identified entities, word features are used define pattern. This pattern each entity category as seed test set. Pattern scoring tuple value score enables generation new patterns have evaluated proposed system for English language dataset tagged (IEER) untagged (CoNLL 2003) corpus Tamil documents FIRE yield an average f-measure 75% both languages."
https://openalex.org/W2461480279,https://doi.org/10.1117/12.2240887,Cross domains Arabic named entity recognition system,2016,"Named Entity Recognition (NER) plays an important role in many Natural Language Processing (NLP) applications such as; Information Extraction (IE), Question Answering (QA), Text Clustering, Summarization and Word Sense Disambiguation. This paper presents the development implementation of domain independent system to recognize three types Arabic named entities. The works based on a set grammar-rules along with part speech tagger addition gazetteers lists trigger words. experimental results shown, that performed as good other systems better some cases cross-domains corpora."
https://openalex.org/W2510347526,https://doi.org/10.1186/s40064-016-3012-9,Performance analysis of CRF-based learning for processing WoT application requests expressed in natural language,2016,"In this paper, we investigate the effectiveness of a CRF-based learning method for identifying necessary Web Things (WoT) application components that would satisfy users' requests issued in natural language. For instance, user request such as ""archive all sports breaking news"" can be satisfied by composing WoT consists ESPN news service and Dropbox storage service.We built an engine identify recognizing main act (MA) or named entities (NEs) from given request. We trained with descriptions applications (called recipes) were collected IFTTT platform. hosts over 300 offer thousands functions referred to triggers actions. There are more than 270,000 publicly-available recipes composed those real users. Therefore, set these is well-qualified training our MA NE recognition engine.We share unique experience generating test recipe assess performance language method. Based on evaluation, introduce further research directions."
https://openalex.org/W2574995332,https://doi.org/10.1109/ictai.2016.0159,NEREA: Named Entity Recognition and Disambiguation Exploiting Local Document Repositories,2016,"In this work, we describe the design, development, and deployment of NEREA (Named Entity Recognizer for spEcific Areas), an automatic Named Disambiguation system, developed in collaboration with professional documentalists. The aim is to keep accurate current information about entities mentioned a local repository, then support building appropriate infoboxes, setting out main data these entities. It achieves high performance thanks use classification resources belonging database. With aim, system performs tasks named entity recognition disambiguation by using three types knowledge bases: resources, global databases like DBpedia, its own catalog created NEREA. proposed method has been validated two different datasets operation tested English Spanish. working methodology being applied real environment media promising results."
https://openalex.org/W2740879578,https://doi.org/10.18653/v1/w17-1104,Aligning Entity Names with Online Aliases on Twitter,2017,"This paper presents new models that automatically align online aliases with their real entity names. Many research applications rely on identifying names in text, but people often refer to entities unexpected nicknames and aliases. For example, The King James are for Lebron James, a professional basketball player. Recent work linking attempts resolve mentions knowledge base entries, like wikipedia page, is unfortunately limited well-known pre-built pages. asks more basic question: can be aligned without background of the entity? Further, semantics surrounding alias used inform alignments? We describe statistical make decisions based lexicographic properties semantic context large corpus tweets. experiment database Twitter users usernames, present first human evaluation this task. Alignment accuracy approaches performance at 81%, we show while features most important, an further improves classification accuracy."
https://openalex.org/W2757888939,https://doi.org/10.14569/ijacsa.2017.080954,DBpedia based Ontological Concepts Driven Information Extraction from Unstructured Text,2017,"In this paper a knowledge base concept driven named entity recognition (NER) approach is presented. The technique used for information extraction from news articles and linking it with background concepts in base. work specifically focuses on extracting mentions unstructured articles. of based the existing DBPedia ontology, representing associated present Wikipedia A collection through structured DBpedia ontology has been extracted developed. For processing text, Dawn have scrapped, preprocessed thereby corpus built. proposed system shows that given an article, identifies text article how they can automatically be linked to corresponding their respective pages Wikipedia. evaluated three test collections politics, sports entertainment domains. experimental results respect are reported. presented as precision, recall f-measure, where precision relevant identified yields best little variation percent f-measures. Additionally, facts both form sentences Resource Description Framework (RDF) triples so enhance user’s understanding related article."
https://openalex.org/W2766983764,https://doi.org/10.26483/ijarcs.v8i8.4801,ENGLISH TO HINDI TRANSLITERATION SYSTEM USING COMBINATION-BASED APPROACH,2017,"Transliteration plays a very significant role in machine translation, which has many applications such as cross-lingual information retrieval, communication, question-answering etc. The main objective of this research paper is to provide method for transliteration named entities from English Hindi language. proposed consists two modules, both apply phoneme-based approach transliterate entities. For transliteration, Module-I utilizes CMU Pronouncing dictionary, collection 133270 words along with their pronunciation. If the word be transliterated not found Module-II used. based on 5-gram model, maximum five letters (two left, right and one target letter) are used generate letter. system been tested database 2408 North-Indian names. Google Input tool Windows comparative study system. accuracy 70.22% against 58.73% tool."
https://openalex.org/W2773655913,https://doi.org/10.26615/978-954-452-049-6_067,A Domain and Language Independent Named Entity Classification Approach Based on Profiles and Local Information,2017,"This paper presents a Named Entity Classification system, which employs machine learning. Our methodology local entity information and profiles as feature set. All features are generated in an unsupervised manner. It is tested on two different data sets: (i) DrugSemantics Spanish corpus (Overall F1 = 74.92), whose results in-line with the state of art without employing external domain-specific resources. And, (ii) English CONLL2003 dataset 81.40), although our lower than previous work, these reached knowledge or complex linguistic analysis. Last, using same configuration for corpora, difference overall only 6.48 points (DrugSemantics 74.92 versus CoNLL2003 81.40). Thus, this result supports hypothesis that approach language domain independent does not require any"
https://openalex.org/W2885678784,https://doi.org/10.18653/v1/w18-2408,NEWS 2018 Whitepaper,2018,"Transliteration is defined as phonetic translation of names across languages. Named Entities (NEs) necessary in many applications, such machine translation, corpus alignment, cross-language IR, information extraction and automatic lexicon acquisition. All systems call for high-performance transliteration, which the focus shared task NEWS 2018 workshop. The objective to promote transliteration research by providing a common benchmarking platform community evaluate state-of-the-art technologies."
https://openalex.org/W2895174221,https://doi.org/10.1007/978-3-030-03146-6_116,Cross Script Hindi English NER Corpus from Wikipedia,2018,"The text generated on social media platforms is essentially a mixed lingual text. mixing of language in any form produces considerable amount difficulty processing systems. Moreover, the advancements research depends upon availability standard corpora. development Indian Named Entity Recognition (NER) systems are facing obstacles due to unavailability evaluation Such corpora may be nature which written using multiple languages predominantly single script only. motivation our work emphasize automatic generation such kind order encourage NER. paper presents preparation Cross Script Hindi-English Corpora from Wikipedia category pages. successfully annotated CoNLL-2003 categories PER, LOC, ORG, and MISC. Its carried out variety machine learning algorithms favorable results achieved."
https://openalex.org/W2974169385,https://doi.org/10.48550/arxiv.1909.09270,Named Entity Recognition with Partially Annotated Training Data,2019,"Supervised machine learning assumes the availability of fully-labeled data, but in many cases, such as low-resource languages, only data available is partially annotated. We study problem Named Entity Recognition (NER) with annotated training which a fraction named entities are labeled, and all other tokens, or otherwise, labeled non-entity by default. In order to train on this noisy dataset, we need distinguish between true false negatives. To end, introduce constraint-driven iterative algorithm that learns detect negatives set downweigh them, resulting weighted set. With set, NER model. evaluate our variants neural non-neural models 8 languages from several language script families, showing strong ability learn partial data. Finally, show real-world efficacy, Bengali corpus non-speakers, outperforming prior state-of-the-art over 5 points F1."
https://openalex.org/W2975429742,https://doi.org/10.1145/3341981.3344250,"Sentence Retrieval for Entity List Extraction with a Seed, Context, and Topic",2019,We present a variation of the corpus-based entity set expansion and list completion task. A user-specified query sentence containing one seed are input to The output is sentences that contain other instances class indicated by input. construct semantic model leverages topical context around scores sentences. proposed finds 46% target retrieving 20 on average. It achieves 16% improvement over BM25 in terms recall@20.
https://openalex.org/W3008973353,https://doi.org/10.34028/iajit/17/2/11,Empirical Evaluation of Leveraging Named Entities for Arabic Sentiment Analysis,2020,"Social media reflects the attitudes of public towards specific events. Events are often related to persons, locations or organizations, so-called Named Entities (NEs). This can define NEs as sentiment-bearing components. In this paper, we dive beyond recognition exploitation sentiment-annotated in Arabic sentiment analysis. Therefore, develop an algorithm detect based on majority them. enabled tagging with proper tags and, thus, including them a analysis framework two models: supervised and lexicon-based. Both models were applied datasets multi-dialectal content. The results revealed that have no considerable impact model, while employing lexicon-based model improved classification performance outperformed most baseline systems."
https://openalex.org/W3024457643,https://doi.org/10.1109/access.2020.2994247,Leveraging Concept-Enhanced Pre-Training Model and Masked-Entity Language Model for Named Entity Disambiguation,2020,"Named Entity Disambiguation (NED) refers to the task of resolving multiple named entity mentions in an input-text sequence their correct references a knowledge graph. We tackle NED problem by leveraging two novel objectives for pre-training framework, and propose model. Especially, proposed model consists of: (i) concept-enhanced pre-training, aiming at identifying valid lexical semantic relations with concept constraints derived from external resource Probase; (ii) masked language model, train contextualized embedding predicting randomly entities based on words non-masked given input-text. Therefore, could merge advantage mechanism generating superiority (e.g., emphasized here) understanding semantic. conduct experiments CoNLL dataset TAC dataset, various datasets provided GERBIL platform. The experimental results demonstrate that achieves significantly higher performance than previous models."
https://openalex.org/W3030936646,,Establishing a New State-of-the-Art for French Named Entity Recognition,2020,"The French TreeBank developed at the University Paris 7 is main source of morphosyntactic and syntactic annotations for French. However, it does not include explicit information related to named entities, which are among most useful several natural language processing tasks applications. Moreover, no large-scale corpus with entity contain referential information, complement type span each mention an indication refers to. We have manually annotated such after automatic pre-annotation step. sketch underlying annotation guidelines we provide a few figures about resulting annotations."
https://openalex.org/W3089628516,https://doi.org/10.11591/ijece.v11i2.pp1689-1696,Machine learning model for clinical named entity recognition,2021,"To extract important concepts (named entities) from clinical notes, most widely used NLP task is named entity recognition (NER). It found the literature that several researchers have extensively machine learning models for NER.The fundamental tasks among medical data mining are and normalization. Medical different general NER in various ways. Huge number of alternate spellings synonyms create explosion word vocabulary sizes. This reduces medicine dictionary efficiency. Entities often consist long sequences tokens, making harder to detect boundaries exactly. The notes written by clinicians less structured minimal grammatical form with cryptic short hand. Because this, it poses challenges recognition. Generally, systems either rule based or pattern based. rules patterns not generalizable because diverse writing style clinicians. use approach resolve these issues focus on choosing effective features classifier building. In this work, has been a required manner"
https://openalex.org/W3096507976,https://doi.org/10.1145/3423337.3429437,Normalisation of 16th and 17th century texts in French and geographical named entity recognition,2020,"Both statistical and rule-based methods for named entity recognition are quite sensitive to the type of language used in analysed texts. Former studies have shown example that it was harder detect entities SMS or microblog messages where words abridged changed lowercase. In this article, we focus on old French texts evaluate impact manual automatic normalisation before applying five geographical tools, as well an improved version one them, order help building maps displaying locations mentioned ancient Our results show leads better all performs differently depending tool extract entities, but with a significant improvement most methods."
https://openalex.org/W3102956241,https://doi.org/10.1007/978-3-319-95450-9_20,Named Entity Recognition System for Sindhi Language,2019,"Named Entity Recognition (NER) System aims to extract the existing information into following categories such as: Persons Name, Organization, Location, Date and Time, Term, Designation Short forms. Now, it is considered be important aspect for many natural languages processing (NLP) tasks retrieval system, machine translation extraction system question answering. Even at a surface level, understanding of named entities involved in document gives richer analytical framework cross referencing. It has been used different Arabic Script-Based like, Arabic, Persian Urdu but, Sindhi could not come being yet. This paper explains problem NER Language provides relevant solution. The developed tag ten Entities. We have Ruled based approach Language. For training testing, 936 words were calculated performance accuracy 98.71%."
https://openalex.org/W3105662392,https://doi.org/10.18653/v1/2020.findings-emnlp.60,Toward Recognizing More Entity Types in NER: An Efficient Implementation using Only Entity Lexicons,2020,"In this work, we explore the way to quickly adjust an existing named entity recognition (NER) system make it capable of recognizing types not defined in system. As illustrative example, consider case that a NER has been built recognize person and organization names, now requires additionally job titles. Such situation is common industrial areas, where required vary lot different products keep changing. To avoid laborious data labeling achieve fast adaptation, propose using previously labeled lexicons newly introduced types. We formulate such task as partially supervised learning problem accordingly effective algorithm solve problem. Comprehensive experimental studies on several public datasets validate effectiveness our method."
https://openalex.org/W3106756765,https://doi.org/10.1109/access.2020.3040182,A Boundary Assembling Method for Nested Biomedical Named Entity Recognition,2020,"Biomedical named entity recognition (BNER) is an important task in biomedical natural language processing, which neologisms (new terms, words) are coined constantly. Most of the existing work can only identify entities with flattened structures and ignore nested discontinuous entities. Because domains often use to represent semantic information entities, methods fail utilize abundant when processing texts. This paper focuses on identifying using a boundary assembly (BA) model, cascading framework consisting three steps. First, start end boundaries identified then assembled into candidates. Finally, classifier implemented for filtering false Our approach effective handling nesting problems tasks. It improves performance considerably, achieving F1-score 81.34% GENIA dataset."
https://openalex.org/W3113392375,https://doi.org/10.1088/1742-6596/1693/1/012161,A Military Named Entity Recognition Method based on pre-training language model and BiLSTM-CRF,2020,"Abstract Military named entity recognition is the basis of military intelligence analysis and operational information service. In order to solve problems inaccurate word segmentation, diverse forms lack corpus in texts, author proposes a method based on Pre-training language model. On this basis, taking advantage Bi-directional Long Short-Term Memory (BiLSTM) neural network dealing with wide range contextual information, BERT-BiLSTM-CRF model was constructed. The experimental results tagged text show that extraction effect better than traditional methods."
https://openalex.org/W3115842509,https://doi.org/10.18653/v1/2020.coling-main.36,Leveraging HTML in Free Text Web Named Entity Recognition,2020,"HTML tags are typically discarded in free text Named Entity Recognition from Web pages. We investigate whether these might be used to improve NER performance. compare Text+Tags sentences with their Text-Only equivalents, over five datasets, two segmentation granularities and models. find an increased F1 performance for of between 0.9% 13.2% all variants This increase, datasets varying entity types, density construction quality, indicates our method is flexible adaptable. These findings imply that a similar technique use other Web-aware NLP tasks, including the enrichment deep language"
https://openalex.org/W4214535912,https://doi.org/10.1021/acs.jcim.1c01199,Single Model for Organic and Inorganic Chemical Named Entity Recognition in ChemDataExtractor,2022,"Chemical Named Entity Recognition (NER) forms the basis of information extraction tasks in chemical domain. However, while such can involve multiple domains chemistry at same time, currently available named entity recognizers are specialized one part chemistry, resulting workflows failing for a biased subset mentions. This paper presents single model that performs close to state-of-the-art both organic (CHEMDNER, 89.7 F1 score) and inorganic (Matscholar, 88.0 NER time. Our system utilizing Bert architecture is as ChemDataExtractor 2.1, along with data sets scripts used train model."
https://openalex.org/W4287776694,https://doi.org/10.48550/arxiv.2005.10200,BERTweet: A pre-trained language model for English Tweets,2020,"We present BERTweet, the first public large-scale pre-trained language model for English Tweets. Our having same architecture as BERT-base (Devlin et al., 2019), is trained using RoBERTa pre-training procedure (Liu 2019). Experiments show that BERTweet outperforms strong baselines RoBERTa-base and XLM-R-base (Conneau 2020), producing better performance results than previous state-of-the-art models on three Tweet NLP tasks: Part-of-speech tagging, Named-entity recognition text classification. release under MIT License to facilitate future research applications data. available at https://github.com/VinAIResearch/BERTweet"
https://openalex.org/W2251316131,https://doi.org/10.18653/v1/k15-1014,Entity Linking Korean Text: An Unsupervised Learning Approach using Semantic Relations,2015,"Although entity linking is a widely researched topic, the same cannot be said for geared languages other than English. Several limitations including syntactic features and relative lack of resources prevent typical approaches to used as e ectively in general. We describe an system that leverage semantic relations between entities within existing knowledge base learn perform using minimal environment consisting part-of-speech tagger. measure performance our against Korean Wikipedia abstract snippets, DBpedia training. Based on these results, we argue both feasibility possibility extending domains"
https://openalex.org/W2760599605,https://doi.org/10.18653/v1/w17-4405,Constructing an Alias List for Named Entities during an Event,2017,"In certain fields, real-time knowledge from events can help in making informed decisions. order to extract pertinent related an event, it is important identify the named entities and their corresponding aliases event. The problem of identifying that spike has remained unexplored. this paper, we introduce algorithm, EntitySpike, identifies popularity tweets a given time period, constructs alias list for these spiked entities. EntitySpike uses temporal heuristic with similar context occur same period (within minutes) during Each entity encoded as vector using heuristic. We show how entity-vectors be used create list. evaluated our algorithm on dataset temporally ordered single 2013 Grammy Awards show. carried out various experiments were published most name outperforms competitive baseline."
https://openalex.org/W2887915553,https://doi.org/10.18653/v1/w18-3008,Comparison of Representations of Named Entities for Document Classification,2018,"We explore representations for multi-word names in text classification tasks, on Reuters (RCV1) topic and sector classification. find that: the best way to treat is split them into tokens use each token as a separate feature; NEs have more impact than classification; replacing with entity types not an effective strategy; representing by different embeddings proper vs. common nouns does improve results. highlight improvements over state-of-the-art results that our CNN models yield."
https://openalex.org/W2887948051,https://doi.org/10.18653/v1/w18-3218,Multilingual Named Entity Recognition on Spanish-English Code-switched Tweets using Support Vector Machines,2018,This paper describes our system submission for the ACL 2018 shared task on named entity recognition (NER) in code-switched Twitter data. Our best result (F1 = 53.65) was obtained using a Support Vector Machine (SVM) with 14 features combined rule-based post processing.
https://openalex.org/W2946103756,https://doi.org/10.3390/info10050178,Istex: A Database of Twenty Million Scientific Papers with a Mining Tool Which Uses Named Entities,2019,"Istex is a database of twenty million full text scientific papers bought by the French Government for use academic libraries. Papers are usually searched title, authors, keywords or possibly abstract. To authorize new types queries Istex, we implemented system named entity recognition on all and offer users possibility to run searches these entities. After presentation project, detail in this paper with CasEN, cascade graphs, Unitex Software. CasEN exists French, but not English. The first challenge was build short time. results its evaluation showed good Precision measure, even if Recall very good. important project ensure it did return unwanted query. second implementation parse around millions documents. We used dockerized application. Finally, explain also how query resulting Named entities website."
https://openalex.org/W2957104353,https://doi.org/10.33633/jais.v4i1.2096,A Study on Named Entity Recognition with OpenNLP at English Texts,2019,"Named entity recognition is a subject, inside of information retrieval which subdomain natural processing. It pertains to identifying and labeling location, person, organization, etc., text content. provides classifying area, etc. formal informal content it can be used for different purposes as question answering systems removal the relation between events. In this work, named performed one method suggested results are discussed assignment unlabeled name entities by using OpenNLP library with help KNIME program in data set."
https://openalex.org/W2967713415,https://doi.org/10.1088/1757-899x/551/1/012052,A Concise Review of Named Entity Recognition System: Methods and Features,2019,"Named Entity Recognition (NER) is an elementary tool for all application areas in Natural Language Processing (NLP) such as Automatic Summarization, Information Extraction, Retrieval, Text Mining, Machine Translation, Question Answering, and Genetics. NER a task to discover categorises the named entities ('atomic elements') text into predefined classes names of persons, organizations, locations, terminologies time, quantity etc. Different languages may have different morphologies thus involve dissimilar procedures. For example, Arabic system cannot be practically used processing Malay texts due morphological features. The features every language are rich complex donates difficulties implementing actual method develop accurate system. In this paper, we review on three main techniques that commonly well-known Rule-Based, Learning, Hybrid approach. This paper also highlights each technique."
https://openalex.org/W2970605637,https://doi.org/10.18653/v1/d19-1647,“A Buster Keaton of Linguistics”: First Automated Approaches for the Extraction of Vossian Antonomasia,2019,"Attributing a particular property to person by naming another person, who is typically wellknown for the respective property, called Vossian Antonomasia (VA). This subtpye of metonymy, which overlaps with metaphor, has specific syntax and especially frequent in journalistic texts. While identifying interest study stylistics, it also source errors relation fact extraction as an explicitly mentioned entity occurs only metaphorically should not be associated contexts. Despite rather simple syntactic variations, automatic VA was never addressed yet since requires deeper semantic understanding entities underlying relations. In this paper, we propose first method VAs that works completely automatically. Our approaches use named recognition, distant supervision based on Wikidata, bi-directional LSTM postprocessing. The evaluation 1.8 million articles New York Times corpus shows our approach significantly outperforms existing semi-automatic identification more than 30 percentage points precision."
https://openalex.org/W2984016833,https://doi.org/10.11591/ijece.v10i2.pp1544-1551,Myanmar named entity corpus and its use in syllable-based neural named entity recognition,2020,"Myanmar language is a low-resource and this one of the main reasons why Natural Language Processing lagged behind compared to other languages. Currently, there no publicly available named entity corpus for language. As part work, very first manually annotated Named Entity tagged was developed proposed support evaluation extraction. At present, our contains approximately 170,000 name entities 60,000 sentences. This work also contributes various deep neural network architectures on Recognition. Experimental results 10-fold cross validation revealed that syllable-based sequence models without additional feature engineering can give better baseline CRF model. aims discover effectiveness approaches textual processing as well promote future research works understudied"
https://openalex.org/W3007853977,https://doi.org/10.48550/arxiv.2002.08902,Application of Pre-training Models in Named Entity Recognition,2020,"Named Entity Recognition (NER) is a fundamental Natural Language Processing (NLP) task to extract entities from unstructured data. The previous methods for NER were based on machine learning or deep learning. Recently, pre-training models have significantly improved performance multiple NLP tasks. In this paper, firstly, we introduce the architecture and tasks of four common models: BERT, ERNIE, ERNIE2.0-tiny, RoBERTa. Then, apply these by fine-tuning, compare effects different model task. experiment results showed that RoBERTa achieved state-of-the-art MSRA-2006 dataset."
https://openalex.org/W3027785995,,"Bootstrapping Named Entity Recognition in E-Commerce with Positive
  Unlabeled Learning",2020,"Named Entity Recognition (NER) in domains like e-commerce is an understudied problem due to the lack of annotated datasets. Recognizing novel entity types this domain, such as products, components, and attributes, challenging because their linguistic complexity low coverage existing knowledge resources. To address problem, we present a bootstrapped positive-unlabeled learning algorithm that integrates domain-specific features quickly efficiently expand seed dictionary. The model achieves average F1 score 72.02% on dataset product descriptions, improvement 3.63% over baseline BiLSTM classifier, particular exhibits better recall (4.96% average)."
https://openalex.org/W3036779180,https://doi.org/10.1088/1742-6596/1550/3/032149,Named Entity Recognition Method of Brazilian Legal Text based on pre-training model,2020,"Named entity recognition (NER) is a common task in Natural Language Processing (NLP). To this end, we propose novel approach based on pre-training model to complete the sequence labeling tasks by learning large-scale real-world data from Brazilian legal documents. Especially, combining iterated dilated convolution[1] (IDCNN) and Bi-LSTM, develop scalable named Sequence Tagging Model (STM) extensive experiments validate effectiveness of STM for NER tasks. Furthermore, compared with IDCNN-CRF model, experimental results show that better F1 score 93.23%, which provides an important basis"
https://openalex.org/W3037102387,https://doi.org/10.18653/v1/2020.acl-srw.30,Embeddings of Label Components for Sequence Labeling: A Case Study of Fine-grained Named Entity Recognition,2020,"In general, the labels used in sequence labeling consist of different types elements. For example, IOB-format entity labels, such as B-Person and I-Person, can be decomposed into span (B I) type information (Person). However, while most models do not consider label components, shared components across Person, beneficial for prediction. this work, we propose to integrate component embeddings models. Through experiments on English Japanese fine-grained named recognition, demonstrate that proposed method improves performance, especially instances with low-frequency labels."
https://openalex.org/W3089069175,,IRISA System for Entity Detection and Linking at CLEF HIPE 2020,2020,"This note describes IRISA's system for the task of named entity processing on historical newspapers in French. Following a standard detection and linking pipeline, our implements three steps to solve task. Named Entity Recognition (NER) is first performed identify mentions document based Conditional Random Fields classifier. Candidate entities from Wikidata are then generated each mention found, using simple search. Finally, every linked one its candidate so-called step leveraging various string metrics semantic structure improve decisions."
https://openalex.org/W3092094101,https://doi.org/10.15439/2020f24,Named Entity Recognition and Named Entity Linking on Esports Contents,2020,"We built a named entity recognition system on Esports News. established an ontology for Esports-related entities, collected and annotated corpus from 80 articles four different titles. also trained CRF BERT-based recognizer, basic DOTA2 knowledge base, linker that links mentions of entities to in Liquipedia (the Wikipedia), naive web app which serves as demo this entire proof-of-concept system. achieved over 61% overall entity-level F1-score the test set NER task."
https://openalex.org/W3093241321,https://doi.org/10.48550/arxiv.2010.08210,Coarse-to-Fine Pre-training for Named Entity Recognition,2020,"More recently, Named Entity Recognition hasachieved great advances aided by pre-trainingapproaches such as BERT. However, currentpre-training techniques focus on building lan-guage modeling objectives to learn a gen-eral representation, ignoring the named entity-related knowledge. To this end, we proposea NER-specific pre-training framework in-ject coarse-to-fine automatically mined entityknowledge into pre-trained models. Specifi-cally, first warm-up model via an en-tity span identification task training it withWikipedia anchors, which can be deemed asgeneral-typed entities. Then leverage thegazetteer-based distant supervision strategy totrain extract coarse-grained typedentities. Finally, devise self-supervisedauxiliary mine fine-grained namedentity knowledge clustering.Empiricalstudies three public NER datasets demon-strate that our achieves significantimprovements against several base-lines, establishing new state-of-the-art per-formance benchmarks. Besides, weshow gains promising re-sults without using human-labeled trainingdata, demonstrating its effectiveness in label-few and low-resource scenarios"
https://openalex.org/W3172706369,https://doi.org/10.18653/v1/2021.dash-1.10,Data Cleaning Tools for Token Classification Tasks,2021,"Human-in-the-loop systems for cleaning NLP training data rely on automated sieves to isolate potentially-incorrect labels manual review. We have developed a novel technique flagging with high sensitivity in named entity recognition corpora. incorporated our sieve into an end-to-end system corpora, implemented as modular collection of Jupyter notebooks built extensions the Pandas DataFrame library. used this identify incorrect CoNLL-2003 corpus English-language (NER), one most influential corpora NER model research. Unlike previous work that only looked at subset corpus’s validation fold, enabled us examine entire depth. Across corpus, we identified over 1300 (out 35089 corpus). published corrections, along code experiments. are developing repeatable version process open-source"
https://openalex.org/W3174623654,https://doi.org/10.1609/aaai.v35i15.17603,Knowledge-aware Named Entity Recognition with Alleviating Heterogeneity,2021,"Named Entity Recognition (NER) is a fundamental and important research topic for many downstream NLP tasks, aiming at detecting classifying named entities (NEs) mentioned in unstructured text into pre-defined categories. Learning from labeled data only far enough when it comes to domain-specific or temporally-evolving (medical terminologies restaurant names). Luckily, open-source Knowledge Bases (KBs) (Wikidata Freebase) contain NEs that are manually with predefined types different domains, which potentially beneficial identify entity boundaries recognize more accurately. However, the type system of NER task typically independent current KBs thus exhibits heterogeneity issue inevitably, makes matching between original KB (Person matches President KBs) less likely, introduces unintended noises without considering knowledge (Band should be mapped Out_of_Entity_Types restaurant-related task). To better incorporate denoise abundant KBs, we propose new KB-aware framework (KaNa), utilizes type-heterogeneous improve NER. Specifically, an mention along set candidate linked KaNa first uses projection mechanism maps shared space homogenize heterogeneous types. Then, based on projected types, noise detector filters out certain less-confident unsupervised manner. Finally, filtered mention-entity pairs injected model as graph predict answers. The experimental results demonstrate KaNa's state-of-the-art performance five public benchmark datasets domains."
https://openalex.org/W3204256746,https://doi.org/10.1038/s41540-021-00200-x,"NERO: a biomedical named-entity (recognition) ontology with a large, annotated corpus reveals meaningful associations through text embedding",2021,"Machine reading (MR) is essential for unlocking valuable knowledge contained in millions of existing biomedical documents. Over the last two decades1,2, most dramatic advances MR have followed wake critical corpus development3. Large, well-annotated corpora been associated with punctuated methodology and automated extraction systems same way that ImageNet4 was fundamental developing machine vision techniques. This study contributes six components to an advanced, named entity analysis tool biomedicine: (a) a new, Named Entity Recognition Ontology (NERO) developed specifically describing textual entities texts, which accounts diverse levels ambiguity, bridging scientific sublanguages molecular biology, genetics, biochemistry, medicine; (b) detailed guidelines human experts annotating hundreds classes; (c) pictographs all entities, simplify burden annotation curators; (d) original, annotated comprising 35,865 sentences, encapsulate 190,679 43,438 events connecting or more entities; (e) validated, off-the-shelf, recognition (NER) extraction, and; (f) embedding models demonstrate promise associations embedded within this corpus."
https://openalex.org/W3216786839,https://doi.org/10.1007/978-3-030-91669-5_21,Named Entity Recognition Architecture Combining Contextual and Global Features,2021,"Named entity recognition (NER) is an information extraction technique that aims to locate and classify named entities (e.g., organizations, locations,...) within a document into predefined categories. Correctly identifying these phrases plays significant role in simplifying access. However, it remains difficult task because (NEs) have multiple forms they are context-dependent. While the context can be represented by contextual features, global relations often misrepresented those models. In this paper, we propose combination of features from XLNet Graph Convolution Network (GCN) enhance NER performance. Experiments over widely-used dataset, CoNLL 2003, show benefits our strategy, with results competitive state art (SOTA)."
https://openalex.org/W4200058434,https://doi.org/10.1186/s12859-021-04236-y,Improving deep learning method for biomedical named entity recognition by using entity definition information,2021,"Biomedical named entity recognition (NER) is a fundamental task of biomedical text mining that finds the boundaries mentions in and determines their type. To accelerate development NER techniques Spanish, PharmaCoNER organizers launched competition to recognize pharmacological substances, compounds, proteins. usually recognized as sequence labeling task, almost all state-of-the-art methods ignore meaning different types. In this paper, we investigate some introduce types deep learning for apply them 2019 challenge. The each type represented by its definition information.We how use information following two methods: (1) SQuad-style machine reading comprehension (MRC) treat query context predict answer spans entities. (2) Span-level one-pass (SOne) one meaning, which information. All models are trained tested on corpus, performance evaluated strict micro-average precision, recall, F1-score.Entity brings improvements both MRC SOne about 0.003 micro-averaged F1-score. model using achieves best with precision 0.9225, recall 0.9050, an F1-score 0.9137, respectively. It outperforms challenge 0.0032 Compared without manually-crafted features, our obtains 1% improvement F1-score, significant. These results indicate useful NER.Our enhanced achieve F1 score implies has positive impact detection. future, will explore more from knowledge graph."
https://openalex.org/W4220844058,https://doi.org/10.1038/s41598-022-08667-2,Deep learning-based methods for natural hazard named entity recognition,2022,"Natural hazard named entity recognition is a technique used to recognize natural entities from large number of texts. The method can facilitate acquisition hazards information and provide reference for mitigation. has many challenges, such as fast change, multiple types various forms entities. This introduce difficulties in research recognition. To address the above problem, this paper constructed disaster annotated corpus training evaluation model, selected compared several deep learning methods based on word vector features. A automatically mine text features reduce dependence manual rules. compares analyzes models three aspects: pretraining, feature extraction decoding. proposed, namely XLNet-BiLSTM-CRF model. Finally, hotspots papers past 10 years were obtained through After training, precision XLNet-BilSTM-CRF model 92.80%, recall rate 91.74%, F1-score 92.27%. results show that method, which superior other methods, effectively"
https://openalex.org/W4221142212,https://doi.org/10.1093/bioinformatics/btac598,BERN2: an advanced neural biomedical named entity recognition and normalization tool,2022,"In biomedical natural language processing, named entity recognition (NER) and normalization (NEN) are key tasks that enable the automatic extraction of entities (e.g. diseases drugs) from ever-growing literature. this article, we present BERN2 (Advanced Biomedical Entity Recognition Normalization), a tool improves previous neural network-based NER by employing multi-task model NEN models to achieve much faster more accurate inference. We hope our can help annotate large-scale texts for various such as knowledge graph construction.Web service is publicly available at http://bern2.korea.ac.kr. also provide local installation https://github.com/dmis-lab/BERN2.Supplementary data Bioinformatics online."
https://openalex.org/W4239111889,https://doi.org/10.35940/ijitee.k2047.0981119,NLP: Rule based Name Entity Recognition,2019,"Named Entity Recognition (NER) is an information extraction task aimed at identifying and classifying words of a sentence, paragraph or document into predefined categories Entities (NEs). NEs are terms that used to name person, location organization. They also refer the value amount something. NER important tool in almost all NLP application areas out which it very essential Search Engines (Semantic based), Machine Translation, Question-Answering, Indexing for Information Retrieval Automatic Summarization systems. This paper presents Rule-based approach development system Afan Oromo language."
https://openalex.org/W2291797008,https://doi.org/10.5391/jkiis.2015.25.2.111,An Effect of Semantic Relatedness on Entity Disambiguation: Using Korean Wikipedia,2015,"Abstract Entity linking is to link entity's name mentions occurring in t ext corresponding entities within knowledge bases. Since the same entity mention may refer different according their context, needs deal with disambiguation. Most recent works on disambiguation focus semantic related-ness between and attempt integrate related ness prior probabilities term co-occurrence. To best of my knowledge, however, it hard find studies that analyze present pure effects relatedness From experimentation Korean Wikipedia da-ta set, this article empirically evaluates approaches using terms following aspects: (1) difference among measures such as NGD, PMI, Jaccard, Dice,Simpson, (2) influence ambiguities co-occurring mentions' (3) in-dividual collective approaches.Key Words : Linking, Disambiguation, Semantic Relatedness, WikipediaReceived: Nov. 5, 2014Revised Feb. 16, 2015Accepted: Mar. 10, 2015"
https://openalex.org/W2518424456,https://doi.org/10.1093/llc/fqw035,An effective named entity similarity metric for comparing data from multiple sources with varying syntax,2016,"This article describes and demonstrates a named entity similarity metric developed for, currently in use by, the FuzzyPhoto project. The presented is effective at comparing data across syntaxless schemas such as are often encountered Gallery, Library, Archive, Museum collections. efficiency of approach was compared to an existing shown be significant improvement when messy data."
https://openalex.org/W2529150735,https://doi.org/10.5339/qfarc.2016.ictpp3064,Named Entity Disambiguation using Hierarchical Text Categorization,2016,"Named entity extraction is an important step in natural language processing. It aims at finding the entities which are present text such as organizations, places or persons. of a paramount importance when it comes to automatic translation different named translated differently. also very useful for advanced search engines aim searching detailed information regarding specific entity. difficult problem usually requires disambiguation same word might belong depending on context. This work has been conducted ANERCorp database. Arabic database contains four entities: person, organization, location and miscellaneous. The 6099 sentences, out 60% used training 20% validation testing. Our method two main steps: first predicts list sentence level. second each sentence. prediction level done through separating document into sentences using punctuation marks. Subsequently, binary relation between set (x) words (y) created from obtained sentences. A exists if, only (y). category (person, miscellaneous). If several entities, duplicated corresponding one them. then extracts keywords relations hyper concept [1]. decomposes original non-overlapping rectangles highlights rectangle most representative keyword. output sorted hierarchical ordering importance. keyword associated with fed random forest classifier 10000 trees order predict produces probabilities existence within Random Forest [sentence(i)] = (P(Person),P(Organization),P(Location),P(miscellaneous)). probability larger than threshold empirically set. In step, we create lookup table associating database, corresponds For unseen test set, predicted produced, word, produced previously built. Ultimately, intersection lists (at level) will give final case where more this stage, maximum kept. We accuracy 76.58% considering tables When performing reaches 77.96%. conclusion, leads improved results over direct extraction. Future includes use other linguist features improve results. Validation state art databases considered. Acknowledgements contribution was made possible by NPRP grant #06-1220-1-233 Qatar National Research Fund (a member Foundation). statements herein solely responsibility authors. Reference [1] A. Hassaine, S. Mecheter, Jaoua. “Text Categorization Using Hyper Rectangular Keyword Extraction: Application News Articles Classification”. Relational Algebraic Methods Computer Science. Springer International Publishing, 2015. 312–325."
https://openalex.org/W2594124351,https://doi.org/10.1051/matecconf/201710002052,Chinese-Lao Bilingual Named Entity Alignment Research,2017,"Chinese-Lao bilingual NE alignment has a very important significance. Three entity methods are proposed in this paper. Firstly, the paper proposes similarity of fuzzy matching problem. Secondly, we use word sequence pattern to propose Chinese model match Lao method. Then build naive Bayes align and named comparable corpus, by mining knowledge information words entities. In end, rules combine advantages three achieve best results."
https://openalex.org/W2776402768,https://doi.org/10.26615/978-954-452-044-1_007,One model per entity: using hundreds of machine learning models to recognize and normalize biomedical names in text,2017,"We explored a new approach to named entity recognition based on hundreds of machine learning models, each trained distinguish single entity, and showed its application gene name identification (GNI). The rationale for our approach, which we “one model per entity” (OMPE), was that increasing the number models would make task easier individual model. Our training strategy leveraged freely-available database annotations instead manually-annotated corpora. While performance in proof-of-concept disappointing, believe there is enough room improvement such approaches could reach competitive while eliminating cost creating costly"
https://openalex.org/W2782780637,https://doi.org/10.48550/arxiv.1801.05147,Adversarial Learning for Chinese NER from Crowd Annotations,2018,"To quickly obtain new labeled data, we can choose crowdsourcing as an alternative way at lower cost in a short time. But exchange, crowd annotations from non-experts may be of quality than those experts. In this paper, propose approach to performing annotation learning for Chinese Named Entity Recognition (NER) make full use the noisy sequence labels multiple annotators. Inspired by adversarial learning, our uses common Bi-LSTM and private representing annotator-generic -specific information. The information is knowledge entities easily mastered crowd. Finally, build NE tagger based on LSTM-CRF model. experiments, create two data sets NER tasks domains. experimental results show that system achieves better scores strong baseline systems."
https://openalex.org/W2895767618,https://doi.org/10.1088/1742-6596/1087/3/032003,Fine-Grained Named Entity Recognition in Question Answering with DBpedia,2018,"Named Entity Recognition in Question Answer tasks can help the language understanding. Traditional NER task usually solved by a supervised model, which need large number of annotated corpora and extract context information as feature for training, however questions are short sentences, with little information, public corpora. On other hand coarse-grained named entities' types cannot offer enough question In this paper, we propose novel model to address both problems, using distant method. Firstly, use web search obtain more relevant information. Secondly, present greedy n-grams algorithm entity mentions. Finally, kNN classification get fine-gained combining mentions link DBpedia. Experimental results show that our outperforms various state-of-art systems dataset--TREC."
https://openalex.org/W2941026374,https://doi.org/10.14419/ijet.v7i4.38.24311,A Hybrid Bootstrapping Approach for developing Odiya Named Entity Corpora from Wikipedia,2018,"Named Entity Recognition (NER) is considered as very influential undertaking in natural language processing appropriate to Question Answering system, Machine Translation (MT), Information extraction (IE), Retrieval (IR) etc. Basically NER identify and classify different types of proper nouns present inside given file like location name, person number, organization time Although huge amount progress made for Indian languages, still a big problem Odiya Language. also resource constrained till today, this tough find out large accurate corpus training test. Therefore paper, we have utilized Wikipedia develop annotated name entities which quite efficient be dataset further. After evaluation, got promising result with F-score 78.89."
https://openalex.org/W2953284417,https://doi.org/10.48550/arxiv.1809.05157,"On the Strength of Character Language Models for Multilingual Named
  Entity Recognition",2018,"Character-level patterns have been widely used as features in English Named Entity Recognition (NER) systems. However, to date there has no direct investigation of the inherent differences between name and non-name tokens text, nor whether this property holds across multiple languages. This paper analyzes capabilities corpus-agnostic Language Models (CLMs) binary task distinguishing from tokens. We demonstrate that CLMs provide a simple powerful model for capturing these differences, identifying named entity diverse set languages at close performance full NER Moreover, by adding very CLM-based we can significantly improve an off-the-shelf system"
https://openalex.org/W2957144888,https://doi.org/10.5121/csit.2019.90706,HMM-Based Dari Named Entity Recognition for Information Extraction,2019,"Named Entity Recognition (NER) is the fundamental subtask of information extraction systems that labels elements into categories such as persons, organizations or locations. The task NER to detect and classify words are parts sentences. This paper describes a statistical approach modeling in Dari language. Pashto low resources languages, spoken official languages Afghanistan. Unlike other named entity detection approaches differ Dari. Since language there no capitalization for identifying entities. We seek bridge gap between linguistic structure supervised learning model predict sequences paired with sequence tags outputs. corpus was developed from collection news, reports articles based on original orthographic experimental result recognition performance presents 94% accuracy."
https://openalex.org/W2971830381,https://doi.org/10.48550/arxiv.1909.00170,Open Named Entity Modeling from Embedding Distribution,2019,"In this paper, we report our discovery on named entity distribution in a general word embedding space, which helps an open definition multilingual rather than previous closed and constraint entities through dictionary, is usually derived from human labor replies schedule update. Our initial visualization of monolingual embeddings indicates tend to gather together despite types language difference, enable us model all using specific geometric structure inside namely, the hypersphere. For cases, proposed gives description diverse different languages. cross-lingual mapping provides novel way build dataset for resource-poor At last, may be shown as handy clue enhance state-of-the-art recognition systems generally."
https://openalex.org/W2975991548,https://doi.org/10.48550/arxiv.1909.11535,"Learning A Unified Named Entity Tagger From Multiple Partially Annotated
  Corpora For Efficient Adaptation",2019,"Named entity recognition (NER) identifies typed mentions in raw text. While the task is well-established, there no universally used tagset: often, datasets are annotated for use downstream applications and accordingly only cover a small set of types relevant to particular task. For instance, biomedical domain, one corpus might annotate genes, another chemicals, diseases---despite texts each containing references all three entities. In this paper, we propose deep structured model integrate these ""partially annotated"" jointly identify appearing training corpora. By leveraging multiple datasets, can learn robust input representations; by building joint model, it avoids potential conflicts caused combining several models' predictions at test time. Experiments show that proposed significantly outperforms strong multi-task learning baselines when on multiple, partially testing contain tags from more than"
https://openalex.org/W2990343759,https://doi.org/10.1007/978-3-030-39469-1_14,Entity Extraction with Knowledge from Web Scale Corpora,2020,"Entity extraction is an important task in text mining and natural language processing. A popular method for entity by comparing substrings from free against a dictionary of entities. In this paper, we present several techniques as post-processing step improving the effectiveness existing technique. These utilise models trained with web-scale corpora which makes our robust versatile. Experiments show that bring notable improvement on efficiency effectiveness."
https://openalex.org/W3000685722,https://doi.org/10.1504/ijiids.2019.10026240,Improving named entity recognition and disambiguation in news headlines,2019,"In this paper, we present a framework for extraction and disambiguation of hyphenated partially named entities in news headlines. The direct application state-of-the-art entity detection approaches on headlines results significantly degraded performance due to different headline formatting comparison with regular text; mentions; partial mentions. introduce novel that assists existing recognition systems deal introduced challenges. particular, mentions We modify the way increases probability correct knowledge base. Our leverages recent past improve experimental showed presented improves F1-score mention by 12% 9% Stanford Illinois NER systems, whereas is improved 9%, 12%, 7% 5% AIDA, Wikifier, TagMe, YODIE NED respectively."
https://openalex.org/W3033772826,,"Embeddings of Label Components for Sequence Labeling: A Case Study of
  Fine-grained Named Entity Recognition",2020,"In general, the labels used in sequence labeling consist of different types elements. For example, IOB-format entity labels, such as B-Person and I-Person, can be decomposed into span (B I) type information (Person). However, while most models do not consider label components, shared components across Person, beneficial for prediction. this work, we propose to integrate component embeddings models. Through experiments on English Japanese fine-grained named recognition, demonstrate that proposed method improves performance, especially instances with low-frequency labels."
https://openalex.org/W3086782256,https://doi.org/10.1145/3533428,"Development of a Dataset and a Deep Learning Baseline Named Entity Recognizer for Three Low Resource Languages: Bhojpuri, Maithili and Magahi",2020,"In Natural Language Processing (NLP) pipelines, Named Entity Recognition (NER) is one of the preliminary problems, which marks proper nouns and other named entities such as Location, Person, Organization, Disease etc. Such entities, without an NER module, adversely affect performance a machine translation system. helps in overcoming this problem by recognising handling separately, although it can be useful Information Extraction systems also. Bhojpuri, Maithili Magahi are low resource languages, usually known Purvanchal languages. This paper focuses on development benchmark dataset for Machine Translation developed to translate from these languages Hindi annotating parts available corpora with entities. sizes 228373, 157468 56190 tokens, respectively, were annotated using 22 entity labels. The annotation considers coarse-grained labels followed tagset used datasets. We also report Deep Learning baseline that uses LSTM-CNNs-CRF model. lower F 1 -scores tool obtained Conditional Random Fields models 70.56% 73.19% 84.18% Magahi. Learning-based technique (LSTM-CNNs-CRF) achieved 61.41% 71.38% 86.39% As results show, fails outperform case Bhojpuri Maithili, have more data terms number but not However, cross-lingual model training performed better than CRF."
https://openalex.org/W3094908526,https://doi.org/10.1101/2020.11.05.368969,"NERO: A Biomedical Named-entity (Recognition) Ontology with a Large, Annotated Corpus Reveals Meaningful Associations Through Text Embedding",2020,"Machine reading is essential for unlocking valuable knowledge contained in the millions of existing biomedical documents. Over last two decades 1,2 , most dramatic advances machine-reading have followed wake critical corpus development 3 . Large, well-annotated corpora been associated with punctuated machine methodology and automated extraction systems same way that ImageNet 4 was fundamental developing vision techniques. This study contributes six components to an advanced, named-entity analysis tool biomedicine: (a) a new, Named-Entity Recognition Ontology (NERO) developed specifically describing entities texts, which accounts diverse levels ambiguity, bridging scientific sublanguages molecular biology, genetics, biochemistry, medicine; (b) detailed guidelines human experts annotating hundreds classes; (c) pictographs all named entities, simplify burden annotation curators; (d) original, annotated comprising 35,865 sentences, encapsulate 190,679 43,438 events connecting or more entities; (e) validated, off-the-shelf, recognition extraction, and; (f) embedding models demonstrate promise associations embedded within this corpus."
https://openalex.org/W3097825955,,IRISA System for Entity Detection and Linking at CLEF HIPE 2020,2020,"This note describes IRISA's system for the task of named entity processing on historical newspapers in French. Following a standard detection and linking pipeline, our implements three steps to solve task. Named Entity Recognition (NER) is first performed identify mentions document based Conditional Random Fields classifier. Candidate entities from Wikidata are then generated each mention found, using simple search. Finally, every linked one its candidate so-called step leveraging various string metrics semantic structure improve decisions."
https://openalex.org/W3107540134,https://doi.org/10.5121/csit.2020.101407,Domain-Transferable Method for Named Entity Recognition Task,2020,"Named Entity Recognition (NER) is a fundamental task in the fields of natural language processing and information extraction. NER has been widely used as standalone tool or an essential component variety applications such question answering, dialogue assistants knowledge graphs development. However, training reliable models requires large amount labelled data which expensive to obtain, particularly specialized domains. This paper describes method learn domain-specific model for arbitrary set named entities when supervision not available. We assume that can be obtained with no human effort, neural from each other. The code, are publicly"
https://openalex.org/W3108651832,https://doi.org/10.5121/csit.2020.101520,Evaluating Dutch Named Entity Recognition and De-Identification Methods in the Human Resource Domain,2020,"The human resource (HR) domain contains various types of privacy-sensitive textual data, such as e-mail correspondence and performance appraisal. Doing research on these documents brings several challenges, one them anonymisation. In this paper, we evaluate the current Dutch text de-identification methods for HR in three steps. First, by updating with latest named entity recognition (NER) models. result is that NER model based CoNLL 2002 corpus combination BERTje transformer give best suppressing persons (recall 0.94) locations 0.82). For gender, DEDUCE performing 0.53). Second evaluation both strict entities (a person must be suppressed a person) third loose sense (no matter what how suppressed, long it suppressed)."
https://openalex.org/W3116158468,https://doi.org/10.15407/pp2016.02-03.150,Machine-learning methods for text named entity recognition,2016,"The article describes machine learning methods for the named entity recognition. To build classifiers two basic models of learning, Naїve Bayes and Conditional Random Fields, were used. A model multi-classification entities using Error Correcting Output Codes was also researched. paper a method classifiers' training results test experiments. Fields overcome other in precision recall evaluations."
https://openalex.org/W3153973346,https://doi.org/10.14712/00326585.012,Text Summarization of Czech News Articles Using Named Entities,2021,"The foundation for the research of summarization in Czech language was laid by work Straka et al. (2018). They published SumeCzech, a large news-based dataset, and proposed several baseline approaches. However, it is clear from achieved results that there space improvement. In our work, we focus on impact named entities news articles. First, annotate SumeCzech with entities. We propose new metric ROUGE_NE measures overlap between true generated summaries, show still challenging systems to reach high score it. an extractive approach Named Entity Density selects sentence highest ratio number length as summary article. experiments reached close solid domain articles selecting first sentence. Moreover, demonstrate selected reflects style reports concisely identifying whom, when, where, what happened. such beneficial combination article voice applications presenting two abstractive approaches based Seq2Seq architecture. uses tokens second has access entity annotations. both exceed state-of-the-art previously reported (2018), latter achieving slightly better SumeCzech's out-of-domain testing set."
https://openalex.org/W3156772763,https://doi.org/10.18653/v1/2021.eacl-main.166,Multilingual Entity and Relation Extraction Dataset and Model,2021,"We present a novel dataset and model for multilingual setting to approach the task of Joint Entity Relation Extraction. The SMiLER consists 1.1 M annotated sentences, representing 36 relations, 14 languages. To best our knowledge, this is currently both largest most comprehensive type. introduce HERBERTa, pipeline that combines two independent BERT models: one sequence classification, other entity tagging. achieves micro F1 81.49 English on dataset, which close current SOTA CoNLL, SpERT."
https://openalex.org/W3157698477,https://doi.org/10.1145/3412841.3442100,Structurally enriched entity mention embedding from semi-structured textual content,2021,"In this research, we propose a novel and effective entity mention embedding framework that learns from semi-structured text corpus with annotated mentions without the aid of well-constructed knowledge graph or external semantic information other than itself. Based on co-occurrence words mentions, enrich matrix entity-entity, entity-word, word-entity relationships as well simple structures within documents. Experimentally, show our proposed benefits structural in link prediction task measured by mean reciprocal rank (MRR) precision@K (MP@K) two datasets for Named-entity recognition (NER)."
https://openalex.org/W3172805258,https://doi.org/10.18653/v1/2021.textgraphs-1.14,Fine-grained General Entity Typing in German using GermaNet,2021,"Fine-grained entity typing is important to tasks like relation extraction and knowledge base construction. We find however, that fine-grained systems perform poorly on general entities (e.g. “ex-president”) as compared named “Barack Obama”). This due a lack of in existing training data sets. show this problem can be mitigated by automatically generating from WordNets. use German WordNet equivalent, GermaNet, generate for typing. supplement train neural system. leads 10% improvement accuracy the prediction level 1 FIGER types entities, while decreasing type only 1%."
https://openalex.org/W3178934116,https://doi.org/10.48550/arxiv.2107.02282,Weakly Supervised Named Entity Tagging with Learnable Logical Rules,2021,"We study the problem of building entity tagging systems by using a few rules as weak supervision. Previous methods mostly focus on disambiguation types based contexts and expert-provided rules, while assuming spans are given. In this work, we propose novel method TALLOR that bootstraps high-quality logical to train neural tagger in fully automated manner. Specifically, introduce compound composed from simple increase precision boundary detection generate more diverse pseudo labels. further design dynamic label selection strategy ensure quality therefore avoid overfitting tagger. Experiments three datasets demonstrate our outperforms other weakly supervised even rivals state-of-the-art distantly with lexicon over 2,000 terms when starting only 20 rules. Our can serve tool for rapidly taggers emerging domains tasks. Case studies show learned potentially explain predicted entities."
https://openalex.org/W3194228729,https://doi.org/10.18653/v1/2021.emnlp-main.820,Robustness Evaluation of Entity Disambiguation Using Prior Probes: the Case of Entity Overshadowing,2021,"Entity disambiguation (ED) is the last step of entity linking (EL), when candidate entities are reranked according to context they appear in. All datasets for training and evaluating models EL consist convenience samples, such as news articles tweets, that propagate prior probability bias distribution towards more frequently occurring entities. It was previously shown performance systems on overestimated since it possible obtain higher accuracy scores by merely learning prior. To provide a adequate evaluation benchmark, we introduce ShadowLink dataset, which includes 16K short text snippets annotated with mentions. We evaluate report popular benchmark. The results show considerable difference in between less common all under evaluation, demonstrating effects overshadowing."
https://openalex.org/W3197571043,https://doi.org/10.3233/ssw210041,Annotating Entities with Fine-Grained Types in Austrian Court Decisions,2021,"The usage of Named Entity Recognition tools on domain-specific corpora is often hampered by insufficient training data. We investigate an approach to produce fine-grained named entity annotations a large corpus Austrian court decisions from small manually annotated data set. apply general purpose model common coarse-grained types. Next, sample these are inspected domain experts initial To efficiently use the set we formulate task typing as binary classification – for each originally occurrence entity, and type verify if belongs it. For this train transformer-based classifier. randomly 547 predictions evaluate them manually. incorrect used improve performance classifier corrected added experiments show that re-training with even very number (5 or 10) can significantly performance. finally all available re-annotate whole"
https://openalex.org/W3198169955,https://doi.org/10.3390/sym13091596,HTLinker: A Head-to-Tail Linker for Nested Named Entity Recognition,2021,"Named entity recognition (NER) aims to extract entities from unstructured text, and a nested structure often exists between entities. However, most previous studies paid more attention flair named while ignoring The importance of words in the text should vary for different categories. In this paper, we propose head-to-tail linker NER. proposed model exploits extracted head as conditional information locate corresponding tails under This strategy takes part symmetric boundary condition effectively leverages improve effectiveness. considers variability semantic correlation tokens heads To verify effectiveness model, numerous experiments were implemented on three datasets: ACE2004, ACE2005, GENIA, with F1-scores 80.5%, 79.3%, 76.4%, respectively. experimental results show that our is effective all methods used comparison."
https://openalex.org/W3199819670,https://doi.org/10.48550/arxiv.2109.07118,"Low-Resource Named Entity Recognition Based on Multi-hop Dependency
  Trigger",2021,This paper presents a simple and effective approach in low-resource named entity recognition (NER) based on multi-hop dependency trigger. Dependency trigger refer to salient nodes relative the graph of context sentence. Our main observation is that there often exists which play an important role recognize location type Previous research has used manual labelling contribution propose use syntactic parser automatically annotate Experiments two English datasets (CONLL 2003 BC5CDR) show proposed method comparable previous trigger-based NER model.
https://openalex.org/W3199871245,https://doi.org/10.21203/rs.3.rs-911654/v1,Disease Named Entity Recognition (D-NER) Evaluation,2021,"Abstract Named Entity Recognition (NER) is a key task in Natural Language Processing (NLP). In medical domain, NER very important phase all end-to-end systems. this paper, we investigate the performance of for disease (D-NER). TaggerOne was evaluated on 52 cardiovascular-related clinical case reports against hand annotation diseases. Different training sets have been used to evaluate as famous tool biomedical domain."
https://openalex.org/W3201563486,https://doi.org/10.18653/v1/2021.law-1.18,WikiGUM: Exhaustive Entity Linking for Wikification in 12 Genres,2021,"Previous work on Entity Linking has focused resources targeting non-nested proper named entity mentions, often in data from Wikipedia, i.e. Wikification. In this paper, we present and evaluate WikiGUM, a fully wikified dataset, covering all mentions of entities, including their non-named pronominal as well nested within other mentions. The dataset covers broad range 12 written spoken genres, most which have not been included efforts to date, leading poor performance by pretrained SOTA system our evaluation. availability variety annotations for the same also enables further research entities context."
https://openalex.org/W3203167191,https://doi.org/10.5808/gi.21018,Improving classification of low-resource COVID-19 literature by using Named Entity Recognition,2021,"Automatic document classification for highly interrelated classes is a demanding task that becomes more challenging when there little labeled data training. Such the case of coronavirus disease 2019 (COVID-19) Clinical repository-a repository classified and translated academic articles related to COVID-19 relevant clinical practice-where 3-way scheme being applied literature. During 7th Biomedical Linked Annotation Hackathon (BLAH7) hackathon, we performed experiments explore use named-entity-recognition (NER) improve classification. We processed literature with OntoGene's Entity Recogniser (OGER) used resulting identified Named Entities (NE) their links major biological databases as extra input features classifier. compared results baseline model without OGER extracted features. In these proof-of-concept experiments, observed clear gain on particular, NE's origin was useful classify types type specialties. Due limitations small dataset, can only conclude our suggests NER would benefit this task. order accurately estimate benefit, further larger dataset be needed."
https://openalex.org/W3205598244,https://doi.org/10.18653/v1/2021.findings-emnlp.388,Cross-Domain Data Integration for Named Entity Disambiguation in Biomedical Text,2021,"Named entity disambiguation (NED), which involves mapping textual mentions to structured entities, is particularly challenging in the medical domain due presence of rare entities. Existing approaches are limited by coarse-grained structural resources biomedical knowledge bases as well use training datasets that provide low coverage over uncommon resources. In this work, we address these issues proposing a cross-domain data integration method transfers from general text base domain. We utilize our scheme augment and generate large NED dataset for pretraining. Our pretrained model with injected achieves state-of-the-art performance on two benchmark datasets: MedMentions BC5CDR. Furthermore, improve entities up 57 accuracy points."
https://openalex.org/W3212915674,https://doi.org/10.26615/978-954-452-072-4_073,BERT-PersNER: a New Model for Persian Named Entity Recognition,2021,"Named entity recognition (NER) is one of the major tasks in natural language processing. A named often a word or expression that bears valuable piece information, which can be effectively employed by some NLP such as machine translation, question answering, and text summarization. In this paper, we introduce new model called BERT-PersNER (BERT based Persian Entity Recognizer), have applied transfer learning active approaches to NER Persian, regarded low-resource language. Like many others, used Conditional Random Field for tag decoding our proposed architecture. has outperformed two available studies NER, most cases experiments using supervised approach on datasets Arman Peyma. Besides, very first effort try only 30% 20% Peyma, respectively achieved 92.15%, 92.41% performance mentioned experiments."
https://openalex.org/W3213788830,https://doi.org/10.26615/978-954-452-072-4_065,Transfer learning for Czech Historical Named Entity Recognition,2021,"Nowadays, named entity recognition (NER) achieved excellent results on the standard corpora. However, big issues are emerging with a need for an application in specific domain, because it requires suitable annotated corpus adapted NE tag-set. This is particularly evident historical document processing field. The main goal of this paper consists proposing and evaluation several transfer learning methods to increase score Czech NER. We study information sources, we use two neural nets modeling recognition. employ corpora our methods, namely corpus. show that BERT representation fine-tuning only simple classifier trained union achieves results."
https://openalex.org/W3214106240,https://doi.org/10.26615/978-954-452-072-4_100,"NEREL: A Russian Dataset with Nested Named Entities, Relations and Events",2021,"In this paper, we present NEREL, a Russian dataset for named entity recognition and relation extraction. NEREL is significantly larger than existing datasets: to date it contains 56K annotated entities 39K relations. Its important difference from previous datasets annotation of nested entities, as well relations within at the discourse level. can facilitate development novel models that extract between on both sentence document levels. also events involving their roles in events. The collection available via https://github.com/nerel-ds/NEREL."
https://openalex.org/W3214495055,https://doi.org/10.48550/arxiv.2109.07449,WikiGUM: Exhaustive Entity Linking for Wikification in 12 Genres,2021,"Previous work on Entity Linking has focused resources targeting non-nested proper named entity mentions, often in data from Wikipedia, i.e. Wikification. In this paper, we present and evaluate WikiGUM, a fully wikified dataset, covering all mentions of entities, including their non-named pronominal as well nested within other mentions. The dataset covers broad range 12 written spoken genres, most which have not been included efforts to date, leading poor performance by pretrained SOTA system our evaluation. availability variety annotations for the same also enables further research entities context."
https://openalex.org/W3214642209,https://doi.org/10.26615/978-954-452-072-4_119,Transfer-based Enrichment of a Hungarian Named Entity Dataset,2021,"In this paper, we present a major update to the first Hungarian named entity dataset, Szeged NER corpus. We used zero-shot cross-lingual transfer initialize enrichment of types annotated in corpus using three neural models: two them based on English OntoNotes and one Czech Named Entity Corpus finetuned from multilingual language models. The output models was automatically merged with original annotation, manually corrected further enriched additional like qualifiers for various types. evaluation performance OntoNotes-based transformer-based new model trained training part final release model."
https://openalex.org/W3217082021,https://doi.org/10.5121/csit.2021.111917,Unsupervised Named Entity Recognition for Hi-Tech Domain,2021,"This paper presents named entity recognition as a multi-answer QA task combined with contextual natural-language-inference based noise reduction. method allows us to use pre-trained models that have been trained for certain downstream tasks generate unsupervised data, reducing the need manual annotation create tags tokens. For each entity, we provide unique context, such types, definitions, questions and few empirical rules along target text train model domain of our interest. formulation (a) system jointly learn NER-specific features from datasets provided, (b) can extract multiple features, thereby boosting performance existing NER (c) provides business-contextualized definitions reduce ambiguity among similar entities. We conducted numerous tests determine quality created find this data generation obtain clean, noise-free minimal effort time. approach has demonstrated be successful in extracting entities, which are then used subsequent components."
https://openalex.org/W3217527629,https://doi.org/10.48550/arxiv.2111.10584,"Improving Tagging Consistency and Entity Coverage for Chemical
  Identification in Full-text Articles",2021,"This paper is a technical report on our system submitted to the chemical identification task of BioCreative VII Track 2 challenge. The main feature this challenge that data consists full-text articles, while current datasets usually consist only titles and abstracts. To effectively address problem, we aim improve tagging consistency entity coverage using various methods such as majority voting within same articles for named recognition (NER) hybrid approach combines dictionary neural model normalization. In experiments NLM-Chem dataset, show models' performance, particularly in terms recall. Finally, official evaluation challenge, was ranked 1st NER by significantly outperforming baseline more than 80 submissions from 16 teams."
https://openalex.org/W4200302168,https://doi.org/10.4995/jclr.2021.15922,Indirectly Named Entity Recognition,2021,"We define here indirectly named entities, as a term to denote multiword expressions referring known entities by means of periphrasis. While entity recognition is classical task in natural language processing, little attention has been paid and their treatment. In this paper, we try address gap, describing issues related the detection understanding texts. introduce proof concept for retrieving both lexicalised non-lexicalised French also show example cases where applied, discuss future perspectives. have initiated creation first lexicon 712 entries that available research."
https://openalex.org/W4205312732,https://doi.org/10.3390/make4010003,NER in Archival Finding Aids: Extended,2022,"The amount of information preserved in Portuguese archives has increased over the years. These documents represent a national heritage high importance, as they portray country’s history. Currently, most have made their finding aids available to public digital format, however, these data do not any annotation, so it is always easy analyze content. In this work, Named Entity Recognition solutions were created that allow identification and classification several named entities from archival aids. translate into crucial about context and, with confidence results, can be used for purposes, example, creation smart browsing tools by using entity linking record techniques. order achieve result scores, we annotated corpora train our own Machine Learning algorithms domain. We also different architectures, such CNNs, LSTMs, Maximum Entropy models. Finally, all datasets ML models developed web platform, NER@DI."
https://openalex.org/W4206693969,https://doi.org/10.3390/app12010491,Analysis of the Full-Size Russian Corpus of Internet Drug Reviews with Complex NER Labeling Using Deep Learning Neural Networks and Language Models,2022,"The paper presents the full-size Russian corpus of Internet users’ reviews on medicines with complex named entity recognition (NER) labeling pharmaceutically relevant entities. We evaluate accuracy levels reached this by a set advanced deep learning neural networks for extracting mentions these markup includes following entities: medication (33,005 mentions), adverse drug reaction (1778), disease (17,403), and note (4490). Two them—medication disease—include attributes. A part has coreference annotation 1560 chains in 300 documents. multi-label model based language features been developed recognizing entities presented corpus. analyze how choice different components affects accuracy. Those include methods vector representation words, types models pre-trained language, ways text normalization, other pre-processing methods. sufficient size our allows us to study effects particularities balancing. compare existing ones occurrences show that balancing number texts without event (ADR) improves ADR no notable decline detecting types. As result, state art pharmacological extraction task is established labeled For type, achieved 61.1% F1-exact metric, which par level corpora similar characteristics representativeness. relation evaluated 71%, higher than results Russian-language corpora."
https://openalex.org/W4221151981,https://doi.org/10.48550/arxiv.2203.03903,"InstructionNER: A Multi-Task Instruction-Based Generative Framework for
  Few-shot NER",2022,"Recently, prompt-based methods have achieved significant performance in few-shot learning scenarios by bridging the gap between language model pre-training and fine-tuning for downstream tasks. However, existing prompt templates are mostly designed sentence-level tasks inappropriate sequence labeling objectives. To address above issue, we propose a multi-task instruction-based generative framework, named InstructionNER, low-resource entity recognition. Specifically, reformulate NER task as generation problem, which enriches source sentences with task-specific instructions answer options, then inferences entities types natural language. We further two auxiliary tasks, including extraction typing, enable to capture more boundary information of deepen understanding type semantics, respectively. Experimental results show that our method consistently outperforms other baselines on five datasets settings."
https://openalex.org/W4224240460,https://doi.org/10.48550/arxiv.2204.09081,Named Entity Recognition for Partially Annotated Datasets,2022,"The most common Named Entity Recognizers are usually sequence taggers trained on fully annotated corpora, i.e. the class of all words for entities is known. Partially some but not types annotated, too noisy training since same entity may be one time with its true type another time, misleading tagger. Therefore, we comparing three strategies partially datasets and an approach to derive new classes from Wikipedia without time-consuming manual data annotation. In order properly verify that our acquisition approaches plausible, manually test two classes, namely food drugs."
https://openalex.org/W4224316287,https://doi.org/10.48550/arxiv.2204.01175,"A Part-of-Speech Tagger for Yiddish: First Steps in Tagging the Yiddish
  Book Center Corpus",2022,"We describe the construction and evaluation of a part-of-speech tagger for Yiddish (the first one, to best our knowledge). This is step in larger project automatically assigning tags syntactic structure text purposes linguistic research. combine two resources current work - an 80K word subset Penn Parsed Corpus Historical (PPCHY) (Santorini, 2021) 650 million words OCR'd from Book Center (YBC). compute embeddings on YBC corpus, these are used with model trained evaluated PPCHY. orthography corpus has many spelling inconsistencies, we present some evidence that even simple non-contextualized able capture relationships among variants without need ""standardize"" corpus. evaluate performance 10-fold cross-validation split, embeddings, showing improve performance. However, great deal remains be done, conclude by discussing next steps, including additional annotated training test data."
https://openalex.org/W4225300672,https://doi.org/10.48550/arxiv.2204.13743,HiNER: A Large Hindi Named Entity Recognition Dataset,2022,"Named Entity Recognition (NER) is a foundational NLP task that aims to provide class labels like Person, Location, Organisation, Time, and Number words in free text. Entities can also be multi-word expressions where the additional I-O-B annotation information helps label them during NER process. While English European languages have considerable annotated data for task, Indian lack on front -- both terms of quantity following standards. This paper releases significantly sized standard-abiding Hindi dataset containing 109,146 sentences 2,220,856 tokens, with 11 tags. We discuss statistics all their essential detail an in-depth analysis tag-set used our data. The show healthy per-tag distribution, especially prominent classes Location Organisation. Since proof resource-effectiveness building models resource testing model benchmark against leader-board entries shared tasks, we do same aforesaid use different language perform sequence labelling efficacy by performing comparative evaluation trained another available task. Our achieve weighted F1 score 88.78 tags 92.22 when collapse tag-set, as discussed paper. To best knowledge, no meets standards volume (amount) variability (diversity), far concerned. fill this gap through work, which hope will help Hindi. release code at https://github.com/cfiltnlp/HiNER"
https://openalex.org/W4225435143,https://doi.org/10.48550/arxiv.2203.15101,Federated Named Entity Recognition,2022,"We present an analysis of the performance Federated Learning in a paradigmatic natural-language processing task: Named-Entity Recognition (NER). For our evaluation, we use language-independent CoNLL-2003 dataset as benchmark and Bi-LSTM-CRF model NER model. show that federated training reaches almost same centralized model, though with some degradation learning environments become more heterogeneous. also convergence rate models for NER. Finally, discuss existing challenges NLP applications can foster future research directions."
https://openalex.org/W4225537045,,KIND: an Italian Multi-Domain Dataset for Named Entity Recognition,2021,"In this paper we present KIND, an Italian dataset for Named-Entity Recognition. It contains more than one million tokens with the annotation covering three classes: persons, locations, and organizations. Most of (around 600K tokens) manual gold annotations in different domains: news, literature, political discourses. Texts are downloadable free from Github repository."
https://openalex.org/W4225776966,,"Chemical Identification and Indexing in PubMed Articles via BERT and
  Text-to-Text Approaches",2021,"The Biocreative VII Track-2 challenge consists of named entity recognition, entity-linking (or entity-normalization), and topic indexing tasks -- with entities topics limited to chemicals for this challenge. Named recognition is a well-established problem we achieve our best performance BERT-based BioMegatron models. We extend approach the linking task. After second stage pretraining BioBERT metric-learning loss strategy called self-alignment (SAP), link based on cosine similarity between their SAP-BioBERT word embeddings. Despite success experiments, find chemical task generally more challenging. In addition conventional NER methods, attempt both novel text-to-text or ""prompt"" method that uses generative language models such as T5 GPT. encouraging results new approach."
https://openalex.org/W4225794827,https://doi.org/10.18653/v1/2022.acl-long.67,Parallel Instance Query Network for Named Entity Recognition,2022,"Named entity recognition (NER) is a fundamental task in natural language processing. Recent works treat named as reading comprehension task, constructing type-specific queries manually to extract entities. This paradigm suffers from three issues. First, can only one type of entities per inference, which inefficient. Second, the extraction for different types isolated, ignoring dependencies between them. Third, query construction relies on external knowledge and difficult apply realistic scenarios with hundreds types. To deal them, we propose Parallel Instance Query Network (PIQN), sets up global learnable instance sentence parallel manner. Each predicts entity, by feeding all simultaneously, parallel. Instead being constructed knowledge, learn their semantics during training. For training model, label assignment one-to-many Linear Assignment Problem (LAP) dynamically assign gold minimal cost. Experiments both nested flat NER datasets demonstrate that our proposed method outperforms previous state-of-the-art models."
https://openalex.org/W4226048468,,"ANEA: Automated (Named) Entity Annotation for German Domain-Specific
  Texts",2021,"Named entity recognition (NER) is an important task that aims to resolve universal categories of named entities, e.g., persons, locations, organizations, and times. Despite its common viable use in many cases, NER barely applicable domains where general are suboptimal, such as engineering or medicine. To facilitate domain-specific types, we propose ANEA, automated (named) annotator assist human annotators creating corpora for German text collections when given a set texts. In our evaluation, find ANEA automatically identifies terms best represent the texts' content, groups coherent terms, extracts assigns descriptive labels these groups, i.e., annotates datasets into domain entities."
https://openalex.org/W4226176989,https://doi.org/10.48550/arxiv.2203.06746,"ProtagonistTagger -- a Tool for Entity Linkage of Persons in Texts from
  Various Languages and Domains",2022,"Named entities recognition (NER) and disambiguation (NED) can add semantic context to the recognized named in texts. entity linkage texts, regardless of a domain, provides links between mentioned unstructured texts individual instances real-world objects. In this poster, we present tool - protagonistTagger for person NER NED The was tested on extracted from classic English novels Polish Internet news. tool's performance (both precision recall) fluctuates 78% even 88%."
https://openalex.org/W4226190198,https://doi.org/10.48550/arxiv.2201.09997,"Razmecheno: Named Entity Recognition from Digital Archive of Diaries
  ""Prozhito""",2022,"The vast majority of existing datasets for Named Entity Recognition (NER) are built primarily on news, research papers and Wikipedia with a few exceptions, created from historical literary texts. What is more, English the main source data further labelling. This paper aims to fill in multiple gaps by creating novel dataset ""Razmecheno"", gathered diary texts project ""Prozhito"" Russian. Our interest lines: studies texts, transfer learning other domains, low-resource or cross-lingual named entity recognition. Razmecheno comprises 1331 sentences 14119 tokens, sampled diaries, written during Perestroika. annotation schema consists five commonly used tags: person, characteristics, location, organisation, facility. labelling carried out crowdsourcing platfrom Yandex.Toloka two stages. First, workers selected sentences, which contain an particular type. Second, they marked up spans. As result 1113 entities were obtained. Empirical evaluation off-the-shelf NER tools fine-tuning pre-trained contextualized encoders. We release annotated open access."
https://openalex.org/W4226198332,https://doi.org/10.48550/arxiv.2203.12907,"Mono vs Multilingual BERT: A Case Study in Hindi and Marathi Named
  Entity Recognition",2022,"Named entity recognition (NER) is the process of recognising and classifying important information (entities) in text. Proper nouns, such as a person's name, an organization's or location's are examples entities. The NER one modules applications like human resources, customer support, search engines, content classification, academia. In this work, we consider for low-resource Indian languages Hindi Marathi. transformer-based models have been widely used tasks. We different variations BERT base-BERT, RoBERTa, AlBERT benchmark them on publicly available Marathi datasets. provide exhaustive comparison monolingual multilingual establish simple baselines currently missing literature. show that MahaRoBERTa model performs best whereas XLM-RoBERTa NER. also perform cross-language evaluation present mixed observations."
https://openalex.org/W4226436348,https://doi.org/10.18653/v1/2022.acl-long.428,Nested Named Entity Recognition as Latent Lexicalized Constituency Parsing,2022,"Nested named entity recognition (NER) has been receiving increasing attention. Recently, (Fu et al, 2021) adapt a span-based constituency parser to tackle nested NER. They treat entities as partially-observed trees and propose the masked inside algorithm for partial marginalization. However, their method cannot leverage heads, which have shown useful in mention detection typing. In this work, we resort more expressive structures, lexicalized constituents are annotated by headwords, model entities. We Eisner-Satta perform marginalization inference efficiently. addition, use (1) two-stage strategy (2) head regularization loss (3) head-aware labeling order enhance performance. make thorough ablation study investigate functionality of each component. Experimentally, our achieves state-of-the-art performance on ACE2004, ACE2005 NNE, competitive GENIA, meanwhile fast speed."
https://openalex.org/W4226501079,https://doi.org/10.48550/arxiv.2112.08808,Simple Questions Generate Named Entity Recognition Datasets,2021,"Recent named entity recognition (NER) models often rely on human-annotated datasets, requiring the significant engagement of professional knowledge target domain and entities. This research introduces an ask-to-generate approach that automatically generates NER datasets by asking questions in simple natural language to open-domain question answering system (e.g., ""Which disease?""). Despite using fewer in-domain resources, our models, solely trained generated largely outperform strong low-resource average F1 score 19.5 for six popular benchmarks. Furthermore, provide competitive performance with rich-resource additionally leverage dictionaries provided experts. In few-shot NER, we previous best model 5.2 three benchmarks achieve new state-of-the-art performance."
https://openalex.org/W4247444884,https://doi.org/10.35940/ijeat.e1055.0785s319,Design of a Rule Based Bio Medical Entity Extractor,2019,The field of Biomedical Entity Extraction/ Identification plays a vital role in Bioinformatics and rapidly growing to meet the needs different text mining tasks. Many biomedical entity extraction tools have been developed so far. This research work has focused develop Rule based Extraction tested with PubMed Medline abstracts Colon cancer Alzheimer disease categories. proposed Extractor gives promising result when compared existing tools. method is incorporating two phases such as preprocessing input document using NLP techniques create rules find out entities regular expression. results are validated well-known Genia tagger Genecards Database. this paper almost good genia tagger. evaluation on corpus achieve an accuracy 92% 88% respectively which identifies more number other
https://openalex.org/W4253099099,https://doi.org/10.35940/ijrte.b3500.078219,"Statistical Method for Named Entity Recognition in Telugu, an Indian Language",2019,"One of the important tasks Natural Language Processing (NLP) is Named Entity Recognition (NER). The primary operation NER to identify proper nouns i.e. locate all named entities in text and tag them as certain entity categories such Entity, Time expression Numeric expression. In previous works, for Telugu language addressed with Conditional Random Fields (CRF) Maximum Entropy models however they failed handle ambiguous tags same entity. This paper presents a hybrid statistical system which are identified by both dictionary-based approach Hidden Markov Model (HMM). proposed method uses Lexicon-lookup dictionary contexts based on semantic features predicting tags. Further HMM used resolve ambiguities predicted present work reports an average accuracy 86.3% finding entities."
https://openalex.org/W4254209484,https://doi.org/10.35940/ijrte.d8067.118419,Issues in Urdu-Hindi NER Output of Google and Bing Translator: An Orthographic Perspective,2019,"Named Entity Recognition (NER) is a sub-task of information extraction in which names are extracted both from the text and linguistic corpora still tough nut to crack for NLP researchers existing Machine Translation (MT) system due its long tail. Since decades, NER has been an area great interest MT computational linguistics, thus, several tools have designed their handling different languages. Therefore, this paper aims compare end user output Google Bing translator with special reference Urdu-Hindi NER. This will provide more insights development intelligent language tools. Thus, on one hand, deals orthographic challenges pertaining UrduHindi general, while other also sheds light transliteration issues particular. Further, we investigated personal names, named entity Urdu, especially ezafat constructions. Consequently, proposes handle engineering point view based quality. Furthermore, ranked scale 0 1, where assigned correct 1 given wrong or inaccurate output."
https://openalex.org/W4281293036,https://doi.org/10.1186/s13326-022-00271-7,An annotated corpus of clinical trial publications supporting schema-based relational information extraction,2022,"Abstract Background The evidence-based medicine paradigm requires the ability to aggregate and compare outcomes of interventions across different trials. This can be facilitated partially automatized by information extraction systems. In order support development systems that extract from published clinical trials at a fine-grained comprehensive level populate knowledge base, we present richly annotated corpus two levels. At first level, entities describe components PICO elements (e.g., population’s age pre-conditions, dosage treatment, etc.) are annotated. second comprises schema-level (i.e., slot-filling templates) annotations corresponding complex other concepts related trial (e.g. relation between an intervention arm, outcome intervention, etc.). Results final includes 211 abstracts with substantial agreement annotators entity scheme level. mean Kappa value for glaucoma T2DM corpora was 0.74 0.68, respectively, single entities. micro-averaged F 1 score measure inter-annotator (i.e. 0.81.The BERT-base baseline method recognition achieved average micro- scores 0.76 0.77 diabetes exact matching. Conclusions this work, have created goes beyond existing corpora, since it is in schematic way represents classes properties defined ontology. Although small, has could used fine-tune pre-trained machine learning models transformers specific task extracting about abstracts.For future will use training entities, predict template slot-fillers class data/object properties) base relies on C-TrO ontology description resulting code inter-annotation publicly available https://zenodo.org/record/6365890."
https://openalex.org/W4281476834,,Wojood: Nested Arabic Named Entity Corpus and Recognition using BERT,2022,"This paper presents Wojood, a corpus for Arabic nested Named Entity Recognition (NER). Nested entities occur when one entity mention is embedded inside another mention. Wojood consists of about 550K Modern Standard (MSA) and dialect tokens that are manually annotated with 21 types including person, organization, location, event date. More importantly, the instead more common flat annotations. The data contains 75K 22.5% which nested. inter-annotator evaluation demonstrated strong agreement Cohen's Kappa 0.979 an F1-score 0.976. To validate our data, we used to train NER model based on multi-task learning AraBERT (Arabic BERT). achieved overall micro 0.884. Our corpus, annotation guidelines, source code pre-trained publicly available."
https://openalex.org/W4281635197,https://doi.org/10.26689/jcer.v6i5.3958,Overview of Named Entity Recognition,2022,"Named entity recognition, as a sub-task of information extraction, has attracted widespread attention from scholars at home and abroad since it was proposed, series studies discussions have been carried out based on it. This paper discusses the existing named recognition technology its history development."
https://openalex.org/W4281718989,,"hmBERT: Historical Multilingual Language Models for Named Entity
  Recognition",2022,"Compared to standard Named Entity Recognition (NER), identifying persons, locations, and organizations in historical texts constitutes a big challenge. To obtain machine-readable corpora, the text is usually scanned Optical Character (OCR) needs be performed. As result, corpora contain errors. Also, entities like location or organization can change over time, which poses another Overall, come with several peculiarities that differ greatly from modern large labeled for training neural tagger are hardly available this domain. In work, we tackle NER German, English, French, Swedish, Finnish by language models. We circumvent need amounts of data using unlabeled pretraining model. propose hmBERT, multilingual BERT-based model, release model versions different sizes. Furthermore, evaluate capability hmBERT solving downstream as part year's HIPE-2022 shared task provide detailed analysis insights. For Multilingual Classical Commentary coarse-grained challenge, our HISTeria outperforms other teams' models two out three languages."
https://openalex.org/W4281721917,https://doi.org/10.1145/3531478,IsiXhosa Named Entity Recognition Resources,2022,"Named entity recognition has been one of the most widely researched natural language processing technologies over last two decades. For South African languages, however, relatively little research and development work done. This changed with release NCHLT named annotated resources, a collection data Conditional Random Field-based recognisers for ten official languages. In this we provide detailed description linguistic analysis (NE) agglutinative isiXhosa language, by analysing morphosyntactic features relevant to three main types NE, viz. person, location, organisation. From identify suffix capitalisation that may be good predictors different NE types. Based on these features, describe recogniser feature set developed as part release. The high precision, 0.9713 overall, but low recall, 0.7409, especially person names, 0.5963, resulting in an overall F-score 0.8406. Although there are various avenues improve recogniser, is significant historically under-resourced language."
https://openalex.org/W4283069714,https://doi.org/10.1145/3511808.3557667,"Personal Entity, Concept, and Named Entity Linking in Conversations",2022,"Building conversational agents that can have natural and knowledge-grounded interactions with humans requires understanding user utterances. Entity Linking (EL) is an effective widely used method for language text connecting it to external knowledge. It is, however, shown existing EL methods developed annotating documents are suboptimal conversations, where personal entities (e.g., ""my cars"") concepts essential In this paper, we introduce a collection tool entity linking in conversations. We collect annotations 1327 utterances, consisting of links named entities, concepts, entities. The dataset training our toolkit linking, CREL. Unlike methods, CREL identify both concepts. also utilizes coreference resolution techniques references the explicit mentions compare state-of-the-art show outperforms all baselines."
https://openalex.org/W4283361265,https://doi.org/10.1007/978-3-031-06555-2_30,A Benchmark of Named Entity Recognition Approaches in Historical Documents Application to 19$$^{th}$$ Century French Directories,2022,"AbstractNamed entity recognition (NER) is a necessary step in many pipelines targeting historical documents. Indeed, such natural language processing techniques identify which class each text token belongs to, e.g. “person name”, “location”, “number”. Introducing new public dataset built from 19th century French directories, we first assess how noisy modern, off-the-shelf OCR are. Then, compare modern CNN- and Transformer-based NER can be reasonably used the context of document analysis. We measure their requirements terms training data, effects noise on performance, show benefit unsupervised pre-training supervised fine-tuning data. Results reproduced using resources available at https://github.com/soduco/paper-ner-bench-das22 https://zenodo.org/record/6394464.KeywordsHistorical documentsNatural processingNamed recognitionOCR noiseAnnotation cost"
https://openalex.org/W4285762938,https://doi.org/10.48550/arxiv.2009.06451,"Development of a Dataset and a Deep Learning Baseline Named Entity
  Recognizer for Three Low Resource Languages: Bhojpuri, Maithili and Magahi",2020,"In Natural Language Processing (NLP) pipelines, Named Entity Recognition (NER) is one of the preliminary problems, which marks proper nouns and other named entities such as Location, Person, Organization, Disease etc. Such entities, without a NER module, adversely affect performance machine translation system. helps in overcoming this problem by recognising handling separately, although it can be useful Information Extraction systems also. Bhojpuri, Maithili Magahi are low resource languages, usually known Purvanchal languages. This paper focuses on development benchmark dataset for Machine Translation developed to translate from these languages Hindi annotating parts their available corpora. corpora sizes 228373, 157468 56190 tokens, respectively, were annotated using 22 entity labels. The annotation considers coarse-grained labels followed tagset used datasets. We also report Deep Learning based baseline that uses an LSTM-CNNs-CRF model. lower F1-scores tool obtained Conditional Random Fields models 96.73 93.33 95.04 Magahi. Learning-based technique (LSTM-CNNs-CRF) achieved 96.25 95.44"
https://openalex.org/W4286859239,,"Focusing on Possible Named Entities in Active Named Entity Label
  Acquisition",2021,"Named entity recognition (NER) aims to identify mentions of named entities in an unstructured text and classify them into the predefined classes. Even though deep learning-based pre-trained language models achieve good predictive performances, many domain-specific NERtasks still require a sufficient amount labeled data. Active learning (AL), general framework for label acquisition problem, has been used NER tasks minimize annotation cost without sacrificing model performance. However, heavily imbalanced class distribution tokens introduces challenges designing effective AL querying methods NER. We propose sentence query evaluation functions which pay more attention possible positive tokens, evaluate these proposed with both sentence-based token-based strategies. also better data-driven normalization approach penalize too long or short sentences. Our experiments on three datasets from different domains reveal that approaches reduce number annotated while achieving comparable prediction performance conventional methods."
https://openalex.org/W4287021471,https://doi.org/10.48550/arxiv.2108.10949,"Robustness Evaluation of Entity Disambiguation Using Prior Probes:the
  Case of Entity Overshadowing",2021,"Entity disambiguation (ED) is the last step of entity linking (EL), when candidate entities are reranked according to context they appear in. All datasets for training and evaluating models EL consist convenience samples, such as news articles tweets, that propagate prior probability bias distribution towards more frequently occurring entities. It was previously shown performance systems on overestimated since it possible obtain higher accuracy scores by merely learning prior. To provide a adequate evaluation benchmark, we introduce ShadowLink dataset, which includes 16K short text snippets annotated with mentions. We evaluate report popular benchmark. The results show considerable difference in between less common all under evaluation, demonstrating effects overshadowing."
https://openalex.org/W4287024323,https://doi.org/10.48550/arxiv.2108.06955,"MobIE: A German Dataset for Named Entity Recognition, Entity Linking and
  Relation Extraction in the Mobility Domain",2021,"We present MobIE, a German-language dataset, which is human-annotated with 20 coarse- and fine-grained entity types linking information for geographically linkable entities. The dataset consists of 3,232 social media texts traffic reports 91K tokens, contains 20.5K annotated entities, 13.1K are linked to knowledge base. A subset the seven mobility-related, n-ary relation types, while remaining documents using weakly-supervised labeling approach implemented Snorkel framework. To best our knowledge, this first that combines annotations NER, EL RE, thus can be used joint multi-task learning these fundamental extraction tasks. make MobIE public at https://github.com/dfki-nlp/mobie."
https://openalex.org/W4287323241,https://doi.org/10.48550/arxiv.2102.13129,ANEA: Distant Supervision for Low-Resource Named Entity Recognition,2021,"Distant supervision allows obtaining labeled training corpora for low-resource settings where only limited hand-annotated data exists. However, to be used effectively, the distant must easy gather. In this work, we present ANEA, a tool automatically annotate named entities in texts based on entity lists. It spans whole pipeline from lists analyzing errors of supervision. A tuning step user improve automatic annotation with their linguistic insights without labelling or checking all tokens manually. six scenarios, show that F1-score can increased by average 18 points through distantly supervised obtained ANEA."
https://openalex.org/W4287688281,https://doi.org/10.48550/arxiv.2008.07347,"HunFlair: An Easy-to-Use Tool for State-of-the-Art Biomedical Named
  Entity Recognition",2020,"Summary: Named Entity Recognition (NER) is an important step in biomedical information extraction pipelines. Tools for NER should be easy to use, cover multiple entity types, highly accurate, and robust towards variations text genre style. To this end, we propose HunFlair, tagger covering types integrated into the widely used NLP framework Flair. HunFlair outperforms other state-of-the-art standalone tools with average gain of 7.26 pp over next best tool, can installed a single command applied only four lines code. Availability: freely available through Flair under MIT license: https://github.com/flairNLP/flair compatible all major operating systems. Contact:{weberple,saengema,alan.akbik}@informatik.hu-berlin.de"
https://openalex.org/W4287721925,https://doi.org/10.48550/arxiv.2007.06897,"What's in a Name? Are BERT Named Entity Representations just as Good for
  any other Name?",2020,"We evaluate named entity representations of BERT-based NLP models by investigating their robustness to replacements from the same typed class in input. highlight that on several tasks while such perturbations are natural, state art trained surprisingly brittle. The brittleness continues even with recent entity-aware BERT models. also try discern cause this non-robustness, considering factors as tokenization and frequency occurrence. Then we provide a simple method ensembles predictions multiple jointly modeling uncertainty type annotations label predictions. Experiments three show our enhances increases accuracy both natural adversarial datasets."
https://openalex.org/W4287776141,https://doi.org/10.48550/arxiv.2005.11184,End-to-end Named Entity Recognition from English Speech,2020,"Named entity recognition (NER) from text has been a widely studied problem and usually extracts semantic information text. Until now, NER speech is mostly in two-step pipeline process that includes first applying an automatic (ASR) system on audio sample then passing the predicted transcript to tagger. In such cases, error does not propagate one step another as both tasks are optimized end-to-end (E2E) fashion. Recent studies confirm integrated approaches (e.g., E2E ASR) outperform sequential ones phoneme based ASR). this paper, we introduce publicly available annotated dataset for English present approach, which jointly optimizes ASR tagger components. Experimental results show proposed approach outperforms classical approach. We also discuss how can be used handle out of vocabulary (OOV) words system."
https://openalex.org/W4287782389,,Soft Gazetteers for Low-Resource Named Entity Recognition,2020,"Traditional named entity recognition models use gazetteers (lists of entities) as features to improve performance. Although modern neural network do not require such hand-crafted for strong performance, recent work has demonstrated their utility on English data. However, designing low-resource languages is challenging, because exhaustive exist in these languages. To address this problem, we propose a method ""soft gazetteers"" that incorporates ubiquitously available information from knowledge bases, Wikipedia, into through cross-lingual linking. Our experiments four show an average improvement 4 points F1 score. Code and data are at https://github.com/neulab/soft-gazetteers."
https://openalex.org/W4287800519,,"Named Entity Recognition without Labelled Data: A Weak Supervision
  Approach",2020,"Named Entity Recognition (NER) performance often degrades rapidly when applied to target domains that differ from the texts observed during training. When in-domain labelled data is available, transfer learning techniques can be used adapt existing NER models domain. But what should one do there no hand-labelled for domain? This paper presents a simple but powerful approach learn in absence of through weak supervision. The relies on broad spectrum labelling functions automatically annotate These annotations are then merged together using hidden Markov model which captures varying accuracies and confusions functions. A sequence finally trained basis this unified annotation. We evaluate two English datasets (CoNLL 2003 news articles Reuters Bloomberg) demonstrate an improvement about 7 percentage points entity-level $F_1$ scores compared out-of-domain neural model."
https://openalex.org/W4287825284,https://doi.org/10.48550/arxiv.2003.09029,NSURL-2019 Task 7: Named Entity Recognition (NER) in Farsi,2020,"NSURL-2019 Task 7 focuses on Named Entity Recognition (NER) in Farsi. This task was chosen to compare different approaches find phrases that specify Entities Farsi texts, and establish a standard testbed for future researches this paper describes the process of making training test data, list participating teams (6 teams), evaluation results their systems. The best system obtained 85.4% F1 score based phrase-level seven classes NEs including person, organization, location, date, time, money percent."
https://openalex.org/W4288256985,https://doi.org/10.48550/arxiv.1908.08983,"A Little Annotation does a Lot of Good: A Study in Bootstrapping
  Low-resource Named Entity Recognizers",2019,"Most state-of-the-art models for named entity recognition (NER) rely on the availability of large amounts labeled data, making them challenging to extend new, lower-resourced languages. However, there are now several proposed approaches involving either cross-lingual transfer learning, which learns from other highly resourced languages, or active efficiently selects effective training data based model predictions. This paper poses question: given this recent progress, and limited human annotation, what is most method creating high-quality recognizers in under-resourced languages? Based extensive experimentation using both simulated real we find a dual-strategy approach best, starting with transferred model, then performing targeted annotation only uncertain spans target language, minimizing annotator effort. Results demonstrate that powerful tool when very little can be annotated, but an entity-targeted strategy achieve competitive accuracy quickly, just one-tenth data."
https://openalex.org/W4288286832,https://doi.org/10.48550/arxiv.1907.03110,ANETAC: Arabic Named Entity Transliteration and Classification Dataset,2019,"In this paper, we make freely accessible ANETAC our English-Arabic named entity transliteration and classification dataset that built from available parallel translation corpora. The contains 79,924 instances, each instance is a triplet (e, a, c), where e the English entity, its Arabic c class can be either Person, Location, or an Organization. mainly aimed for researchers are working on transliteration, but it also used purposes."
https://openalex.org/W4288348920,,"A Joint Named-Entity Recognizer for Heterogeneous Tag-sets Using a Tag
  Hierarchy",2019,"We study a variant of domain adaptation for named-entity recognition where multiple, heterogeneously tagged training sets are available. Furthermore, the test tag-set is not identical to any individual tag-set. Yet, relations between all tags provided in tag hierarchy, covering as combination tags. This setting occurs when various datasets created using different annotation schemes. also case extending with new by annotating only dataset. propose use given hierarchy jointly learn neural network that shares its tagging layer among tag-sets. compare this model combining independent models and based on multitasking approach. Our experiments show benefit tag-hierarchy model, especially facing non-trivial consolidation"
https://openalex.org/W4288804672,https://doi.org/10.48550/arxiv.2207.14094,Entity Type Prediction Leveraging Graph Walks and Entity Descriptions,2022,"The entity type information in Knowledge Graphs (KGs) such as DBpedia, Freebase, etc. is often incomplete due to automated generation or human curation. Entity typing the task of assigning inferring semantic an a KG. This paper presents \textit{GRAND}, novel approach for leveraging different graph walk strategies RDF2vec together with textual descriptions. first generates walks and then uses language model obtain embeddings each node graph. study shows that strategy embedding have significant effect on performance task. proposed outperforms baseline approaches benchmark datasets DBpedia FIGER KGs both fine-grained coarse-grained classes. results show combination order-aware variants contextual descriptions achieve best results."
https://openalex.org/W4289422015,https://doi.org/10.48550/arxiv.1810.03430,Cross Script Hindi English NER Corpus from Wikipedia,2018,"The text generated on social media platforms is essentially a mixed lingual text. mixing of language in any form produces considerable amount difficulty processing systems. Moreover, the advancements research depends upon availability standard corpora. development Indian Named Entity Recognition (NER) systems are facing obstacles due to unavailability evaluation Such corpora may be nature which written using multiple languages predominantly single script only. motivation our work emphasize automatic generation such kind order encourage NER. paper presents preparation Cross Script Hindi-English Corpora from Wikipedia category pages. successfully annotated CoNLL-2003 categories PER, LOC, ORG, and MISC. Its carried out variety machine learning algorithms favorable results achieved."
https://openalex.org/W4294828945,https://doi.org/10.48550/arxiv.2203.10545,Parallel Instance Query Network for Named Entity Recognition,2022,"Named entity recognition (NER) is a fundamental task in natural language processing. Recent works treat named as reading comprehension task, constructing type-specific queries manually to extract entities. This paradigm suffers from three issues. First, can only one type of entities per inference, which inefficient. Second, the extraction for different types isolated, ignoring dependencies between them. Third, query construction relies on external knowledge and difficult apply realistic scenarios with hundreds types. To deal them, we propose Parallel Instance Query Network (PIQN), sets up global learnable instance sentence parallel manner. Each predicts entity, by feeding all simultaneously, parallel. Instead being constructed knowledge, learn their semantics during training. For training model, label assignment one-to-many Linear Assignment Problem (LAP) dynamically assign gold minimal cost. Experiments both nested flat NER datasets demonstrate that our proposed method outperforms previous state-of-the-art models."
https://openalex.org/W4295955218,https://doi.org/10.1109/access.2022.3206539,Dark Web: E-Commerce Information Extraction Based on Name Entity Recognition Using Bidirectional-LSTM,2022,"Information extraction from e-commerce platform is a challenging task. Due to significant increase in number of ecommerce marketplaces, it difficult gain good accuracy by using existing data mining techniques systematically extract key information. The first step toward recognizing entities design an application that detects the unstructured text, known as Named Entity Recognition (NER) application. previous NER solutions are specific for such people, locations, and organizations raw but they limited domain. We proposed Bi-directional LSTM with CNN model detecting entities. represents rich complex knowledge about groups products sold on dark web. Different experiments were conducted compare state-of-the-art baselines. Our approach achieves best performance Dark Web dataset Conll-2003. Results show 96.20% 92.90% Conll-2003 dataset, which compared other cutting-edge approaches."
https://openalex.org/W4297799105,https://doi.org/10.48550/arxiv.1811.02902,"microNER: A Micro-Service for German Named Entity Recognition based on
  BiLSTM-CRF",2018,"For named entity recognition (NER), bidirectional recurrent neural networks became the state-of-the-art technology in recent years. Competing approaches vary with respect to pre-trained word embeddings as well models for character represent sequence information most effectively. NER German language texts, these model variations have not been studied extensively. We evaluate performance of different and on two standard datasets a special focus out-of-vocabulary words. With F-Scores above 82% GermEval'14 dataset 85% CoNLL'03 dataset, we achieve (near) this task. publish several wrapped into micro-service based Docker allow easy integration other applications via JSON API."
https://openalex.org/W4298300545,https://doi.org/10.48550/arxiv.1705.05487,"NeuroNER: an easy-to-use program for named-entity recognition based on
  neural networks",2017,"Named-entity recognition (NER) aims at identifying entities of interest in a text. Artificial neural networks (ANNs) have recently been shown to outperform existing NER systems. However, ANNs remain challenging use for non-expert users. In this paper, we present NeuroNER, an easy-to-use named-entity tool based on ANNs. Users can annotate using graphical web-based user interface (BRAT): the annotations are then used train ANN, which turn predict entities' locations and categories new texts. NeuroNER makes annotation-training-prediction flow smooth accessible anyone."
https://openalex.org/W4301185049,https://doi.org/10.48550/arxiv.1712.08349,Tracking the Diffusion of Named Entities,2017,"Existing studies of how information diffuses across social networks have thus far concentrated on analysing and recovering the spread deterministic innovations such as URLs, hashtags, group membership. However investigating mentions real-world entities appear has yet to be explored, largely due computationally intractable nature performing large-scale entity extraction. In this paper we present, best our knowledge, one first pieces work closely examine diffusion named media, using Reddit case study platform. We investigate can accurately recognised extracted from discussion posts. then use these patterns cascades probability a user adopting an (i.e. mentioning it) is associated with exposures entity. put together by presenting parallelised model that forecast adoption, finding influence adoption between users characterised their prior interactions -- opposed whether propagated entity-adoptions beforehand. Our findings important implications for researchers studying language, community analysts who wish understand entity-level dynamics."
https://openalex.org/W4306353018,https://doi.org/10.48550/arxiv.1909.00426,Global Entity Disambiguation with BERT,2019,"We propose a global entity disambiguation (ED) model based on BERT. To capture contextual information for ED, our treats not only words but also entities as input tokens, and solves the task by sequentially resolving mentions to their referent using resolved inputs at each step. train large entity-annotated corpus obtained from Wikipedia. achieve new state-of-the-art results five standard ED datasets: AIDA-CoNLL, MSNBC, AQUAINT, ACE2004, WNED-WIKI. The source code checkpoint are available https://github.com/studio-ousia/luke."
https://openalex.org/W4306705193,https://doi.org/10.48550/arxiv.2210.07586,"Automatic Creation of Named Entity Recognition Datasets by Querying
  Phrase Representations",2022,"Most weakly supervised named entity recognition (NER) models rely on domain-specific dictionaries provided by experts. This approach is infeasible in many domains where do not exist. While a phrase retrieval model was used to construct pseudo-dictionaries with entities retrieved from Wikipedia automatically recent study, these often have limited coverage because the retriever likely retrieve popular rather than rare ones. In this embedding search efficiently create high-coverage presented. Specifically, reformulation of natural language queries into representations allows space densely populated various entities. addition, we present novel framework, HighGEN, that generates NER datasets obtained using search. HighGEN weak labels based distance between embeddings candidate and target type reduce noise dictionaries. We compare current six benchmarks demonstrate superiority our models."
https://openalex.org/W4307638650,https://doi.org/10.1186/s13326-022-00280-6,We are not ready yet: limitations of state-of-the-art disease named entity recognizers,2022,"Abstract Background Intense research has been done in the area of biomedical natural language processing. Since breakthrough transfer learning-based methods, BERT models are used a variety and clinical applications. For available data sets, these show excellent results - partly exceeding inter-annotator agreements. However, named entity recognition applied on COVID-19 preprints shows performance drop compared to test data. The question arises how well trained able predict completely new data, i.e. generalize. Results Based example disease recognition, we investigate robustness different machine methods thereof learning that current state-of-the-art work for given training corresponding set but experience significant lack generalization when applying Conclusions We argue there is need larger annotated sets testing. Therefore, foresee curation further and, moreover, investigation continual processes models."
